{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62ac3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bb6f9",
   "metadata": {},
   "source": [
    "### Automatic speach recognition with neural networks\n",
    "This notebook uses MFCC pre-prossesing to generate acoustic features to the neural network, and then the neural network can be trained and tested. The baseline consists into HNNs. \n",
    "\n",
    "The dataset utilized in this notebook is the speach commands datasets from tensorflow. As this dataset comes with a lot of words and a lots of examples, we choose to simplify this notebook example by focusing in the following words: cat, dog, happy, house and zero. The training set consists into 25 examples of each word, and the testing set consists into 5 new examples of each word.\n",
    "\n",
    "All the pre-prossecing is made by the spock: . Using this software the user can process WAV files and output the processed acoustic features in `.FEA` files. Then the neural network can receive this accoustic features and output the class that corresponds to the right word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895ab5d",
   "metadata": {},
   "source": [
    "### The first step consists into reading the FEA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a64780",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dir = './output_test/mfcceda39w240s80/features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1a3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fea_to_samples(filename):\n",
    "    # Discard the header with 2048 bytes that yield 512 floats\n",
    "    feat_array = np.fromfile(filename, dtype='>f') [512:]\n",
    "    num_of_paterns = feat_array[0]\n",
    "    space_dimension = feat_array[1]\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    # Jump the first 2 floats\n",
    "    i_s = 2\n",
    "    for pat in range(int(num_of_paterns)):\n",
    "        # Feature Extraction\n",
    "        n_frames = feat_array[i_s]\n",
    "        i_e = space_dimension*n_frames + i_s + 1  \n",
    "        feat = feat_array[i_s+1: int(i_e)].tolist()\n",
    "        i_s = int(i_e)\n",
    "        res.append(feat)\n",
    "    \n",
    "    assert(i_e == len(feat_array))\n",
    "    \n",
    "    # Convert the feature patterns to a np matrix, padding according \n",
    "    # to the biggest entry\n",
    "    max_dim = max([len(row) for row in res])\n",
    "    res_np = np.zeros((int(num_of_paterns), max_dim))\n",
    "    \n",
    "    for pat in range(int(num_of_paterns)):\n",
    "        vec_len = len(res[pat])\n",
    "        res_np[pat][:vec_len] = res[pat] \n",
    "\n",
    "    return res_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e332db",
   "metadata": {},
   "source": [
    "### After reading the FEA files we can organize the network input and desireble output\n",
    "In this supervised learning probblem we must organize matrices that will serve as input or features, and other that will be the desired output or label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a122ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xy_matrices(feat_dir):\n",
    "    files = listdir(feat_dir)\n",
    "    labels = [name[2:-4] for name in listdir(feat_dir)]\n",
    "    x_matrix = fea_to_samples(feat_dir+ '/' +files[0])\n",
    "\n",
    "    y_matrix = np.zeros((x_matrix.shape[0], 1))\n",
    "    y_matrix[:,0] = 0\n",
    "    for file_i in range(1,len(files)):\n",
    "        x_i = fea_to_samples(feat_dir + '/' + files[file_i])\n",
    "        y_i = np.zeros((x_i.shape[0], 1))\n",
    "        y_i[:,0] = file_i\n",
    "        x_matrix = np.concatenate((x_matrix, x_i))\n",
    "        y_matrix = np.concatenate((y_matrix, y_i))\n",
    "\n",
    "    return x_matrix, y_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601faacd",
   "metadata": {},
   "source": [
    "### After that we must organize our dataset object\n",
    "As we are using the Pytorch stack, it is recommended to use the Dataset class to organize the entry and output samples of training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6329e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MfcSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 x_matrix,\n",
    "                 y_matrix,\n",
    "                std_scaler=None,\n",
    "                min_max_scaler=None):\n",
    "        \n",
    "        if std_scaler==None:\n",
    "            # Standard scaling\n",
    "            std_scaler = StandardScaler()\n",
    "            std_scaler.fit(x_matrix)\n",
    "        x_matrix = std_scaler.transform(x_matrix)\n",
    "\n",
    "        if min_max_scaler == None:\n",
    "            # Min max scaling\n",
    "            min_max_scaler = MinMaxScaler()\n",
    "            min_max_scaler.fit(x_matrix)\n",
    "        x_matrix = min_max_scaler.transform(x_matrix)\n",
    "\n",
    "        self.X = x_matrix\n",
    "        self.y = y_matrix\n",
    "        self.std_scaler = std_scaler\n",
    "        self.min_max_scaler = min_max_scaler\n",
    "        self.x_shape = self.X.shape\n",
    "        self.y_shape = self.y.shape\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b5a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(root_dir):\n",
    "    x_train, y_train = generate_xy_matrices(root_dir + '/train')\n",
    "    x_test, y_test = generate_xy_matrices(root_dir + '/test')\n",
    "    feat_scaler = MinMaxScaler()\n",
    "    feat_scaler.fit(x_train)\n",
    "    \n",
    "    train_set = MfcSet(x_train, y_train)\n",
    "    test_set = MfcSet(x_test, y_test, train_set.std_scaler, train_set.min_max_scaler)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1f530",
   "metadata": {},
   "source": [
    "### The multi layer perceptron network\n",
    "In this classification task, is desireble that we use a softmax activation function in the output layer, but as we are using the Pytorch stack, the loss function `CrossEntropyLoss` already apply the softmax for us. Then this is not necessary, as shown in the example bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7683b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "print(input.shape)\n",
    "print(target.shape)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c78c870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3852,  0.2514,  1.5921, -1.3035, -0.3502],\n",
       "        [ 0.0416,  0.6006, -0.3122, -0.7699,  1.1190],\n",
       "        [ 0.0323, -1.1363, -0.5738,  0.8250, -0.1912]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ecc0a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb3a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, num_labels, dp=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_features, 20),\n",
    "            nn.Sigmoid(),  \n",
    "            nn.Linear(20, num_labels),\n",
    "            nn.Dropout(dp)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31eff65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, batch_size, train_loader, criterion, optimizer,\n",
    "          scheduler, set_size):\n",
    "    model.train()\n",
    "    acc = []\n",
    "    loss = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_loss, train_acc = batch_train(model, epoch, batch_size,\n",
    "                                                train_loader, criterion,\n",
    "                                                optimizer, scheduler, set_size)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s |'.format(\n",
    "            epoch, (time.time() - epoch_start_time)))\n",
    "        print('-' * 89)\n",
    "\n",
    "        scheduler.step()\n",
    "        acc.append(train_acc)\n",
    "        loss.append(train_loss)\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36497111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(model, epoch, batch_size, train_loader, criterion, optimizer,\n",
    "                scheduler, set_size):\n",
    "    model.train()  # Turn on the train mode\n",
    "    batch_loss = 0.\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    predictions = torch.tensor([]).to(device)\n",
    "    ground_truth = torch.tensor([]).to(device)\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        data, targets = batch[0], batch[1]\n",
    "        data = Variable(torch.Tensor(data.float())).to(device)\n",
    "        targets = Variable(torch.Tensor(targets.float())).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, torch.flatten(targets.long()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "        total_loss += batch_loss\n",
    "        log_interval = int(set_size / batch_size / 5)\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            cur_loss = batch_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.6f} | {:5.2f} ms | '\n",
    "                  'loss {:5.5f}'.format(epoch, i, set_size // batch_size,\n",
    "                                        scheduler.get_lr()[0],\n",
    "                                        elapsed * 1000 / log_interval,\n",
    "                                        cur_loss))\n",
    "            batch_loss = 0\n",
    "            start_time = time.time()\n",
    "        pred = output\n",
    "        predictions = torch.cat((predictions, pred), 0)\n",
    "        ground_truth = torch.cat((ground_truth, targets), 0)\n",
    "        \n",
    "\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    predictions = np.argmax(predictions, axis=1).reshape(predictions.shape[0], 1)\n",
    "    ground_truth = ground_truth.cpu().cpu().detach().numpy()\n",
    "    acc = accuracy_score(ground_truth, predictions)\n",
    "    return total_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a925ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = build_dataset(feat_dir)\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=5,\n",
    "                          shuffle=True)\n",
    "set_size = train_set.y_shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513801dc",
   "metadata": {},
   "source": [
    "### One example of feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ed9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat, label = next(iter(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f43d8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f43841b8c70>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d38eff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92119d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLP(train_set.x_shape[1], 5).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091de7e",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04cd47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     5/   25 batches | lr 0.010000 |  4.17 ms | loss 2.01490\n",
      "| epoch   1 |    10/   25 batches | lr 0.010000 |  2.16 ms | loss 1.76103\n",
      "| epoch   1 |    15/   25 batches | lr 0.010000 |  2.23 ms | loss 1.64854\n",
      "| epoch   1 |    20/   25 batches | lr 0.010000 |  1.35 ms | loss 1.67666\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.07s |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |     5/   25 batches | lr 0.009604 |  1.93 ms | loss 1.99755\n",
      "| epoch   2 |    10/   25 batches | lr 0.009604 |  1.20 ms | loss 1.68430\n",
      "| epoch   2 |    15/   25 batches | lr 0.009604 |  1.25 ms | loss 1.63784\n",
      "| epoch   2 |    20/   25 batches | lr 0.009604 |  1.20 ms | loss 1.64197\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.03s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-02)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
    "loss, acc =  train(model, 2, 5, train_loader, criterion,\n",
    "      optimizer, scheduler, set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efff9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
