{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62ac3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from transformer.model import TransformerTimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bb6f9",
   "metadata": {},
   "source": [
    "### Automatic speach recognition with neural networks\n",
    "This notebook uses MFCC pre-prossesing to generate acoustic features to the neural network, and then the neural network can be trained and tested. The baseline consists into HNNs. \n",
    "\n",
    "The dataset utilized in this notebook is the speach commands datasets from tensorflow. As this dataset comes with a lot of words and a lots of examples, we choose to simplify this notebook example by focusing in the following words: cat, dog, happy, house and zero. The training set consists into 25 examples of each word, and the testing set consists into 5 new examples of each word.\n",
    "\n",
    "All the pre-prossecing is made by the spock: . Using this software the user can process WAV files and output the processed acoustic features in `.FEA` files. Then the neural network can receive this accoustic features and output the class that corresponds to the right word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895ab5d",
   "metadata": {},
   "source": [
    "### The first step consists into reading the FEA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a64780",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dir = './output_test/mfcceda39w240s80/features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1a3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fea_to_samples(filename):\n",
    "    # Discard the header with 2048 bytes that yield 512 floats\n",
    "    feat_array = np.fromfile(filename, dtype='>f') [512:]\n",
    "    num_of_paterns = feat_array[0]\n",
    "    space_dimension = feat_array[1]\n",
    "    \n",
    "    res = []\n",
    "    # Jump the first 2 floats\n",
    "    i_s = 2\n",
    "    total_frames = []\n",
    "    for pat in range(int(num_of_paterns)):\n",
    "        # Feature Extraction\n",
    "        n_frames = feat_array[i_s]\n",
    "        total_frames.append(n_frames) \n",
    "        i_e = space_dimension*n_frames + i_s + 1  \n",
    "        feat = feat_array[i_s+1: int(i_e)].tolist()\n",
    "        i_s = int(i_e)\n",
    "        res.append(feat)\n",
    "    \n",
    "    assert(i_e == len(feat_array))\n",
    "    \n",
    "    # Convert the feature patterns to a np matrix, padding according \n",
    "    # to the biggest entry\n",
    "    max_dim = max([len(row) for row in res])\n",
    "    res_np = np.zeros((int(num_of_paterns), max_dim))\n",
    "    \n",
    "    for pat in range(int(num_of_paterns)):\n",
    "        vec_len = len(res[pat])\n",
    "        res_np[pat][:vec_len] = res[pat] \n",
    "    \n",
    "    return res_np,(max(total_frames), space_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e332db",
   "metadata": {},
   "source": [
    "### After reading the FEA files we can organize the network input and desireble output\n",
    "In this supervised learning probblem we must organize matrices that will serve as input or features, and other that will be the desired output or label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a122ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xy_matrices(feat_dir):\n",
    "    files = listdir(feat_dir)\n",
    "    labels = [name[2:-4] for name in listdir(feat_dir)]\n",
    "    x_matrix, shape = fea_to_samples(feat_dir+ '/' +files[0])\n",
    "\n",
    "    y_matrix = np.zeros((x_matrix.shape[0], 1))\n",
    "    y_matrix[:,0] = 0\n",
    "    for file_i in range(1,len(files)):\n",
    "        x_i, _ = fea_to_samples(feat_dir + '/' + files[file_i])\n",
    "        y_i = np.zeros((x_i.shape[0], 1))\n",
    "        y_i[:,0] = file_i\n",
    "        x_matrix = np.concatenate((x_matrix, x_i))\n",
    "        y_matrix = np.concatenate((y_matrix, y_i))\n",
    "\n",
    "    return x_matrix, y_matrix, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601faacd",
   "metadata": {},
   "source": [
    "### After that we must organize our dataset object\n",
    "As we are using the Pytorch stack, it is recommended to use the Dataset class to organize the entry and output samples of training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6329e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MfcSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 x_matrix,\n",
    "                 y_matrix,\n",
    "                 shape,\n",
    "                std_scaler=None,\n",
    "                min_max_scaler=None):\n",
    "        \n",
    "        if std_scaler==None:\n",
    "            # Standard scaling\n",
    "            std_scaler = StandardScaler()\n",
    "            std_scaler.fit(x_matrix)\n",
    "        x_matrix = std_scaler.transform(x_matrix)\n",
    "        print(x_matrix.shape)\n",
    "       \n",
    "#         if min_max_scaler == None:\n",
    "#             # Min max scaling\n",
    "#             min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#             min_max_scaler.fit(x_matrix)\n",
    "#         x_matrix = min_max_scaler.transform(x_matrix)\n",
    "        \n",
    "        shape = (int(shape[0]), int(shape[1]))\n",
    "        self.X = x_matrix.reshape((x_matrix.shape[0], shape[0], shape[1]))\n",
    "        self.y = y_matrix\n",
    "        self.std_scaler = std_scaler\n",
    "#         self.min_max_scaler = min_max_scaler\n",
    "        self.x_shape = self.X.shape\n",
    "        self.y_shape = self.y.shape\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b5a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(root_dir):\n",
    "    x_train, y_train, shape = generate_xy_matrices(root_dir + '/train')\n",
    "    x_test, y_test, _ = generate_xy_matrices(root_dir + '/test')\n",
    "    feat_scaler = MinMaxScaler()\n",
    "    feat_scaler.fit(x_train)\n",
    "    \n",
    "    train_set = MfcSet(x_train, y_train, shape)\n",
    "    test_set = MfcSet(x_test, y_test, shape, train_set.std_scaler) #train_set.min_max_scaler)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1f530",
   "metadata": {},
   "source": [
    "### The multi layer perceptron network\n",
    "In this classification task, is desireble that we use a softmax activation function in the output layer, but as we are using the Pytorch stack, the loss function `CrossEntropyLoss` already apply the softmax for us. Then this is not necessary, as shown in the example bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7683b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "print(input.shape)\n",
    "print(target.shape)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c78c870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1839, -0.9449, -0.2581,  0.0082, -1.0579],\n",
       "        [-1.9218, -0.0865,  0.1425, -1.9018,  0.8447],\n",
       "        [-1.2490, -0.9397,  2.0815, -1.3135, -0.3973]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ecc0a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31eff65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, batch_size, train_loader, criterion, optimizer,\n",
    "          scheduler, set_size):\n",
    "    model.train()\n",
    "    acc = []\n",
    "    loss = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_loss, train_acc = batch_train(model, epoch, batch_size,\n",
    "                                                train_loader, criterion,\n",
    "                                                optimizer, scheduler, set_size)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s |'.format(\n",
    "            epoch, (time.time() - epoch_start_time)))\n",
    "        print('-' * 89)\n",
    "\n",
    "        scheduler.step()\n",
    "        acc.append(train_acc)\n",
    "        loss.append(train_loss)\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36497111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(model, epoch, batch_size, train_loader, criterion, optimizer,\n",
    "                scheduler, set_size):\n",
    "    model.train()  # Turn on the train mode\n",
    "    batch_loss = 0.\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    predictions = torch.tensor([]).to(device)\n",
    "    ground_truth = torch.tensor([]).to(device)\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        data, targets = batch[0], batch[1]\n",
    "        data = Variable(torch.Tensor(data.float())).to(device)\n",
    "        targets = Variable(torch.Tensor(targets.float())).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, torch.flatten(targets.long()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "        total_loss += batch_loss\n",
    "        log_interval = int(set_size / batch_size / 5)\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            cur_loss = batch_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.6f} | {:5.2f} ms | '\n",
    "                  'loss {:5.5f}'.format(epoch, i, set_size // batch_size,\n",
    "                                        scheduler.get_lr()[0],\n",
    "                                        elapsed * 1000 / log_interval,\n",
    "                                        cur_loss))\n",
    "            batch_loss = 0\n",
    "            start_time = time.time()\n",
    "        pred = output\n",
    "        predictions = torch.cat((predictions, pred), 0)\n",
    "        ground_truth = torch.cat((ground_truth, targets), 0)\n",
    "        \n",
    "\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    predictions = np.argmax(predictions, axis=1).reshape(predictions.shape[0], 1)\n",
    "    ground_truth = ground_truth.cpu().cpu().detach().numpy()\n",
    "    acc = accuracy_score(ground_truth, predictions)\n",
    "    return total_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a925ebc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 7683)\n",
      "(25, 7683)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_set, test_set = build_dataset(feat_dir)\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(test_set,\n",
    "                          batch_size=test_set.y_shape[0],\n",
    "                          shuffle=True)\n",
    "set_size = train_set.y_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c84b6f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 197, 39)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.x_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513801dc",
   "metadata": {},
   "source": [
    "### One example of feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ed9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat, label = next(iter(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f43d8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d38eff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92119d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TransformerTimeSeries(device,\n",
    "                              n_encoder_time_steps=197,\n",
    "                              encoder_vector_sz=39,\n",
    "                              output_vector_sz=5,\n",
    "                              d_model=100,\n",
    "                              dropout=0,).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091de7e",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04cd47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     1/    6 batches | lr 0.001000 | 94.75 ms | loss 4.50203\n",
      "| epoch   1 |     2/    6 batches | lr 0.001000 | 40.42 ms | loss 1.96584\n",
      "| epoch   1 |     3/    6 batches | lr 0.001000 | 40.19 ms | loss 1.59658\n",
      "| epoch   1 |     4/    6 batches | lr 0.001000 | 43.73 ms | loss 1.55907\n",
      "| epoch   1 |     5/    6 batches | lr 0.001000 | 40.51 ms | loss 1.93594\n",
      "| epoch   1 |     6/    6 batches | lr 0.001000 | 11.67 ms | loss 1.59804\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.27s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |     1/    6 batches | lr 0.000960 | 86.26 ms | loss 3.31398\n",
      "| epoch   2 |     2/    6 batches | lr 0.000960 | 39.59 ms | loss 1.52469\n",
      "| epoch   2 |     3/    6 batches | lr 0.000960 | 44.76 ms | loss 1.64764\n",
      "| epoch   2 |     4/    6 batches | lr 0.000960 | 39.40 ms | loss 1.65395\n",
      "| epoch   2 |     5/    6 batches | lr 0.000960 | 39.48 ms | loss 1.62259\n",
      "| epoch   2 |     6/    6 batches | lr 0.000960 | 11.93 ms | loss 1.91821\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |     1/    6 batches | lr 0.000941 | 94.79 ms | loss 3.14375\n",
      "| epoch   3 |     2/    6 batches | lr 0.000941 | 39.47 ms | loss 1.45406\n",
      "| epoch   3 |     3/    6 batches | lr 0.000941 | 39.35 ms | loss 1.52922\n",
      "| epoch   3 |     4/    6 batches | lr 0.000941 | 39.43 ms | loss 1.50221\n",
      "| epoch   3 |     5/    6 batches | lr 0.000941 | 39.41 ms | loss 1.60372\n",
      "| epoch   3 |     6/    6 batches | lr 0.000941 | 11.74 ms | loss 1.45157\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.27s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |     1/    6 batches | lr 0.000922 | 86.87 ms | loss 2.92728\n",
      "| epoch   4 |     2/    6 batches | lr 0.000922 | 39.42 ms | loss 1.61876\n",
      "| epoch   4 |     3/    6 batches | lr 0.000922 | 39.37 ms | loss 1.38284\n",
      "| epoch   4 |     4/    6 batches | lr 0.000922 | 39.77 ms | loss 1.47969\n",
      "| epoch   4 |     5/    6 batches | lr 0.000922 | 44.46 ms | loss 1.36907\n",
      "| epoch   4 |     6/    6 batches | lr 0.000922 | 11.75 ms | loss 1.54310\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |     1/    6 batches | lr 0.000904 | 86.40 ms | loss 2.84357\n",
      "| epoch   5 |     2/    6 batches | lr 0.000904 | 39.41 ms | loss 1.36449\n",
      "| epoch   5 |     3/    6 batches | lr 0.000904 | 44.39 ms | loss 1.35914\n",
      "| epoch   5 |     4/    6 batches | lr 0.000904 | 39.44 ms | loss 1.22122\n",
      "| epoch   5 |     5/    6 batches | lr 0.000904 | 39.43 ms | loss 1.54812\n",
      "| epoch   5 |     6/    6 batches | lr 0.000904 | 11.81 ms | loss 1.29656\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |     1/    6 batches | lr 0.000886 | 89.98 ms | loss 2.47802\n",
      "| epoch   6 |     2/    6 batches | lr 0.000886 | 40.09 ms | loss 1.21881\n",
      "| epoch   6 |     3/    6 batches | lr 0.000886 | 39.39 ms | loss 1.40932\n",
      "| epoch   6 |     4/    6 batches | lr 0.000886 | 39.38 ms | loss 1.37982\n",
      "| epoch   6 |     5/    6 batches | lr 0.000886 | 39.43 ms | loss 1.21909\n",
      "| epoch   6 |     6/    6 batches | lr 0.000886 | 11.72 ms | loss 1.17549\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   7 |     1/    6 batches | lr 0.000868 | 87.14 ms | loss 2.36352\n",
      "| epoch   7 |     2/    6 batches | lr 0.000868 | 39.40 ms | loss 1.29888\n",
      "| epoch   7 |     3/    6 batches | lr 0.000868 | 39.37 ms | loss 0.90339\n",
      "| epoch   7 |     4/    6 batches | lr 0.000868 | 39.38 ms | loss 1.17503\n",
      "| epoch   7 |     5/    6 batches | lr 0.000868 | 39.34 ms | loss 0.98798\n",
      "| epoch   7 |     6/    6 batches | lr 0.000868 | 12.07 ms | loss 0.91748\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   8 |     1/    6 batches | lr 0.000851 | 87.18 ms | loss 1.85070\n",
      "| epoch   8 |     2/    6 batches | lr 0.000851 | 39.46 ms | loss 0.96624\n",
      "| epoch   8 |     3/    6 batches | lr 0.000851 | 39.46 ms | loss 0.79044\n",
      "| epoch   8 |     4/    6 batches | lr 0.000851 | 46.36 ms | loss 0.96635\n",
      "| epoch   8 |     5/    6 batches | lr 0.000851 | 39.42 ms | loss 0.99891\n",
      "| epoch   8 |     6/    6 batches | lr 0.000851 | 11.71 ms | loss 0.75718\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  0.27s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   9 |     1/    6 batches | lr 0.000834 | 96.33 ms | loss 1.59692\n",
      "| epoch   9 |     2/    6 batches | lr 0.000834 | 39.39 ms | loss 0.77167\n",
      "| epoch   9 |     3/    6 batches | lr 0.000834 | 39.67 ms | loss 0.60554\n",
      "| epoch   9 |     4/    6 batches | lr 0.000834 | 39.32 ms | loss 0.53769\n",
      "| epoch   9 |     5/    6 batches | lr 0.000834 | 39.38 ms | loss 1.04020\n",
      "| epoch   9 |     6/    6 batches | lr 0.000834 | 11.66 ms | loss 1.09113\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  0.27s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  10 |     1/    6 batches | lr 0.000817 | 86.82 ms | loss 1.23751\n",
      "| epoch  10 |     2/    6 batches | lr 0.000817 | 39.37 ms | loss 0.51383\n",
      "| epoch  10 |     3/    6 batches | lr 0.000817 | 39.48 ms | loss 0.33675\n",
      "| epoch  10 |     4/    6 batches | lr 0.000817 | 39.79 ms | loss 0.72917\n",
      "| epoch  10 |     5/    6 batches | lr 0.000817 | 39.38 ms | loss 0.65178\n",
      "| epoch  10 |     6/    6 batches | lr 0.000817 | 11.70 ms | loss 0.51557\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |     1/    6 batches | lr 0.000801 | 83.62 ms | loss 0.75718\n",
      "| epoch  11 |     2/    6 batches | lr 0.000801 | 39.47 ms | loss 0.47788\n",
      "| epoch  11 |     3/    6 batches | lr 0.000801 | 39.42 ms | loss 0.37149\n",
      "| epoch  11 |     4/    6 batches | lr 0.000801 | 39.32 ms | loss 0.44802\n",
      "| epoch  11 |     5/    6 batches | lr 0.000801 | 39.32 ms | loss 0.43594\n",
      "| epoch  11 |     6/    6 batches | lr 0.000801 | 11.70 ms | loss 0.42713\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |     1/    6 batches | lr 0.000785 | 82.32 ms | loss 0.67514\n",
      "| epoch  12 |     2/    6 batches | lr 0.000785 | 39.39 ms | loss 0.27913\n",
      "| epoch  12 |     3/    6 batches | lr 0.000785 | 39.31 ms | loss 0.34132\n",
      "| epoch  12 |     4/    6 batches | lr 0.000785 | 39.38 ms | loss 0.18057\n",
      "| epoch  12 |     5/    6 batches | lr 0.000785 | 39.74 ms | loss 0.34240\n",
      "| epoch  12 |     6/    6 batches | lr 0.000785 | 11.74 ms | loss 0.25352\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  0.25s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |     1/    6 batches | lr 0.000769 | 83.07 ms | loss 0.35023\n",
      "| epoch  13 |     2/    6 batches | lr 0.000769 | 39.43 ms | loss 0.16928\n",
      "| epoch  13 |     3/    6 batches | lr 0.000769 | 39.39 ms | loss 0.33763\n",
      "| epoch  13 |     4/    6 batches | lr 0.000769 | 39.86 ms | loss 0.26207\n",
      "| epoch  13 |     5/    6 batches | lr 0.000769 | 39.42 ms | loss 0.16359\n",
      "| epoch  13 |     6/    6 batches | lr 0.000769 | 14.35 ms | loss 0.04880\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 |     1/    6 batches | lr 0.000754 | 85.41 ms | loss 0.56463\n",
      "| epoch  14 |     2/    6 batches | lr 0.000754 | 39.40 ms | loss 0.13558\n",
      "| epoch  14 |     3/    6 batches | lr 0.000754 | 44.01 ms | loss 0.11510\n",
      "| epoch  14 |     4/    6 batches | lr 0.000754 | 42.29 ms | loss 0.22889\n",
      "| epoch  14 |     5/    6 batches | lr 0.000754 | 39.44 ms | loss 0.16162\n",
      "| epoch  14 |     6/    6 batches | lr 0.000754 | 11.73 ms | loss 0.09873\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  15 |     1/    6 batches | lr 0.000739 | 83.98 ms | loss 0.27549\n",
      "| epoch  15 |     2/    6 batches | lr 0.000739 | 39.37 ms | loss 0.18135\n",
      "| epoch  15 |     3/    6 batches | lr 0.000739 | 39.43 ms | loss 0.11936\n",
      "| epoch  15 |     4/    6 batches | lr 0.000739 | 39.36 ms | loss 0.06953\n",
      "| epoch  15 |     5/    6 batches | lr 0.000739 | 39.38 ms | loss 0.08931\n",
      "| epoch  15 |     6/    6 batches | lr 0.000739 | 11.69 ms | loss 0.05455\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  16 |     1/    6 batches | lr 0.000724 | 95.89 ms | loss 0.11585\n",
      "| epoch  16 |     2/    6 batches | lr 0.000724 | 39.51 ms | loss 0.11530\n",
      "| epoch  16 |     3/    6 batches | lr 0.000724 | 42.51 ms | loss 0.05052\n",
      "| epoch  16 |     4/    6 batches | lr 0.000724 | 40.16 ms | loss 0.06283\n",
      "| epoch  16 |     5/    6 batches | lr 0.000724 | 39.39 ms | loss 0.11082\n",
      "| epoch  16 |     6/    6 batches | lr 0.000724 | 11.69 ms | loss 0.06621\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  0.27s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  17 |     1/    6 batches | lr 0.000709 | 83.25 ms | loss 0.05226\n",
      "| epoch  17 |     2/    6 batches | lr 0.000709 | 39.31 ms | loss 0.04776\n",
      "| epoch  17 |     3/    6 batches | lr 0.000709 | 39.37 ms | loss 0.03305\n",
      "| epoch  17 |     4/    6 batches | lr 0.000709 | 41.90 ms | loss 0.02851\n",
      "| epoch  17 |     5/    6 batches | lr 0.000709 | 39.49 ms | loss 0.05361\n",
      "| epoch  17 |     6/    6 batches | lr 0.000709 | 12.55 ms | loss 0.02427\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  18 |     1/    6 batches | lr 0.000695 | 82.38 ms | loss 0.04909\n",
      "| epoch  18 |     2/    6 batches | lr 0.000695 | 39.37 ms | loss 0.01515\n",
      "| epoch  18 |     3/    6 batches | lr 0.000695 | 39.40 ms | loss 0.03107\n",
      "| epoch  18 |     4/    6 batches | lr 0.000695 | 39.36 ms | loss 0.04189\n",
      "| epoch  18 |     5/    6 batches | lr 0.000695 | 39.46 ms | loss 0.02636\n",
      "| epoch  18 |     6/    6 batches | lr 0.000695 | 12.09 ms | loss 0.04447\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  0.25s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  19 |     1/    6 batches | lr 0.000681 | 88.60 ms | loss 0.04730\n",
      "| epoch  19 |     2/    6 batches | lr 0.000681 | 39.34 ms | loss 0.01982\n",
      "| epoch  19 |     3/    6 batches | lr 0.000681 | 39.37 ms | loss 0.01509\n",
      "| epoch  19 |     4/    6 batches | lr 0.000681 | 39.34 ms | loss 0.01395\n",
      "| epoch  19 |     5/    6 batches | lr 0.000681 | 39.56 ms | loss 0.01026\n",
      "| epoch  19 |     6/    6 batches | lr 0.000681 | 11.67 ms | loss 0.01412\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  20 |     1/    6 batches | lr 0.000668 | 86.93 ms | loss 0.02462\n",
      "| epoch  20 |     2/    6 batches | lr 0.000668 | 39.69 ms | loss 0.01236\n",
      "| epoch  20 |     3/    6 batches | lr 0.000668 | 39.35 ms | loss 0.02066\n",
      "| epoch  20 |     4/    6 batches | lr 0.000668 | 39.39 ms | loss 0.01154\n",
      "| epoch  20 |     5/    6 batches | lr 0.000668 | 39.54 ms | loss 0.01483\n",
      "| epoch  20 |     6/    6 batches | lr 0.000668 | 11.71 ms | loss 0.01512\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  21 |     1/    6 batches | lr 0.000654 | 87.98 ms | loss 0.02614\n",
      "| epoch  21 |     2/    6 batches | lr 0.000654 | 39.39 ms | loss 0.01039\n",
      "| epoch  21 |     3/    6 batches | lr 0.000654 | 39.45 ms | loss 0.01483\n",
      "| epoch  21 |     4/    6 batches | lr 0.000654 | 43.43 ms | loss 0.01084\n",
      "| epoch  21 |     5/    6 batches | lr 0.000654 | 39.32 ms | loss 0.00661\n",
      "| epoch  21 |     6/    6 batches | lr 0.000654 | 11.72 ms | loss 0.00465\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  22 |     1/    6 batches | lr 0.000641 | 87.84 ms | loss 0.01420\n",
      "| epoch  22 |     2/    6 batches | lr 0.000641 | 39.39 ms | loss 0.01228\n",
      "| epoch  22 |     3/    6 batches | lr 0.000641 | 39.76 ms | loss 0.00819\n",
      "| epoch  22 |     4/    6 batches | lr 0.000641 | 39.39 ms | loss 0.00889\n",
      "| epoch  22 |     5/    6 batches | lr 0.000641 | 39.40 ms | loss 0.00757\n",
      "| epoch  22 |     6/    6 batches | lr 0.000641 | 11.67 ms | loss 0.00157\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  23 |     1/    6 batches | lr 0.000628 | 82.22 ms | loss 0.01527\n",
      "| epoch  23 |     2/    6 batches | lr 0.000628 | 39.59 ms | loss 0.00531\n",
      "| epoch  23 |     3/    6 batches | lr 0.000628 | 39.40 ms | loss 0.00867\n",
      "| epoch  23 |     4/    6 batches | lr 0.000628 | 39.37 ms | loss 0.00852\n",
      "| epoch  23 |     5/    6 batches | lr 0.000628 | 39.87 ms | loss 0.00683\n",
      "| epoch  23 |     6/    6 batches | lr 0.000628 | 11.70 ms | loss 0.00254\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  0.25s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  24 |     1/    6 batches | lr 0.000616 | 83.60 ms | loss 0.01500\n",
      "| epoch  24 |     2/    6 batches | lr 0.000616 | 46.80 ms | loss 0.00485\n",
      "| epoch  24 |     3/    6 batches | lr 0.000616 | 43.19 ms | loss 0.00650\n",
      "| epoch  24 |     4/    6 batches | lr 0.000616 | 39.44 ms | loss 0.00684\n",
      "| epoch  24 |     5/    6 batches | lr 0.000616 | 39.44 ms | loss 0.00728\n",
      "| epoch  24 |     6/    6 batches | lr 0.000616 | 11.69 ms | loss 0.00572\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  0.27s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  25 |     1/    6 batches | lr 0.000603 | 83.85 ms | loss 0.01202\n",
      "| epoch  25 |     2/    6 batches | lr 0.000603 | 39.72 ms | loss 0.00849\n",
      "| epoch  25 |     3/    6 batches | lr 0.000603 | 41.83 ms | loss 0.00511\n",
      "| epoch  25 |     4/    6 batches | lr 0.000603 | 39.87 ms | loss 0.00847\n",
      "| epoch  25 |     5/    6 batches | lr 0.000603 | 39.34 ms | loss 0.00359\n",
      "| epoch  25 |     6/    6 batches | lr 0.000603 | 12.61 ms | loss 0.00948\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  26 |     1/    6 batches | lr 0.000591 | 87.89 ms | loss 0.01306\n",
      "| epoch  26 |     2/    6 batches | lr 0.000591 | 39.42 ms | loss 0.00596\n",
      "| epoch  26 |     3/    6 batches | lr 0.000591 | 39.44 ms | loss 0.00367\n",
      "| epoch  26 |     4/    6 batches | lr 0.000591 | 39.72 ms | loss 0.00497\n",
      "| epoch  26 |     5/    6 batches | lr 0.000591 | 39.40 ms | loss 0.00534\n",
      "| epoch  26 |     6/    6 batches | lr 0.000591 | 11.71 ms | loss 0.00936\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  27 |     1/    6 batches | lr 0.000580 | 84.48 ms | loss 0.00881\n",
      "| epoch  27 |     2/    6 batches | lr 0.000580 | 39.39 ms | loss 0.00591\n",
      "| epoch  27 |     3/    6 batches | lr 0.000580 | 39.41 ms | loss 0.00561\n",
      "| epoch  27 |     4/    6 batches | lr 0.000580 | 39.43 ms | loss 0.00578\n",
      "| epoch  27 |     5/    6 batches | lr 0.000580 | 39.40 ms | loss 0.00424\n",
      "| epoch  27 |     6/    6 batches | lr 0.000580 | 11.72 ms | loss 0.00481\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  28 |     1/    6 batches | lr 0.000568 | 82.44 ms | loss 0.00900\n",
      "| epoch  28 |     2/    6 batches | lr 0.000568 | 39.37 ms | loss 0.00592\n",
      "| epoch  28 |     3/    6 batches | lr 0.000568 | 39.36 ms | loss 0.00539\n",
      "| epoch  28 |     4/    6 batches | lr 0.000568 | 39.32 ms | loss 0.00341\n",
      "| epoch  28 |     5/    6 batches | lr 0.000568 | 39.72 ms | loss 0.00465\n",
      "| epoch  28 |     6/    6 batches | lr 0.000568 | 11.71 ms | loss 0.00307\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time:  0.25s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  29 |     1/    6 batches | lr 0.000557 | 82.58 ms | loss 0.00873\n",
      "| epoch  29 |     2/    6 batches | lr 0.000557 | 43.82 ms | loss 0.00334\n",
      "| epoch  29 |     3/    6 batches | lr 0.000557 | 39.38 ms | loss 0.00521\n",
      "| epoch  29 |     4/    6 batches | lr 0.000557 | 39.44 ms | loss 0.00508\n",
      "| epoch  29 |     5/    6 batches | lr 0.000557 | 39.39 ms | loss 0.00285\n",
      "| epoch  29 |     6/    6 batches | lr 0.000557 | 11.70 ms | loss 0.00094\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  30 |     1/    6 batches | lr 0.000545 | 84.05 ms | loss 0.00827\n",
      "| epoch  30 |     2/    6 batches | lr 0.000545 | 39.42 ms | loss 0.00363\n",
      "| epoch  30 |     3/    6 batches | lr 0.000545 | 39.36 ms | loss 0.00520\n",
      "| epoch  30 |     4/    6 batches | lr 0.000545 | 39.37 ms | loss 0.00433\n",
      "| epoch  30 |     5/    6 batches | lr 0.000545 | 39.45 ms | loss 0.00316\n",
      "| epoch  30 |     6/    6 batches | lr 0.000545 | 11.66 ms | loss 0.00231\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  31 |     1/    6 batches | lr 0.000535 | 82.54 ms | loss 0.00731\n",
      "| epoch  31 |     2/    6 batches | lr 0.000535 | 39.36 ms | loss 0.00413\n",
      "| epoch  31 |     3/    6 batches | lr 0.000535 | 39.57 ms | loss 0.00450\n",
      "| epoch  31 |     4/    6 batches | lr 0.000535 | 39.42 ms | loss 0.00308\n",
      "| epoch  31 |     5/    6 batches | lr 0.000535 | 43.21 ms | loss 0.00392\n",
      "| epoch  31 |     6/    6 batches | lr 0.000535 | 11.69 ms | loss 0.00581\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  32 |     1/    6 batches | lr 0.000524 | 89.58 ms | loss 0.00696\n",
      "| epoch  32 |     2/    6 batches | lr 0.000524 | 39.38 ms | loss 0.00268\n",
      "| epoch  32 |     3/    6 batches | lr 0.000524 | 43.22 ms | loss 0.00333\n",
      "| epoch  32 |     4/    6 batches | lr 0.000524 | 39.64 ms | loss 0.00344\n",
      "| epoch  32 |     5/    6 batches | lr 0.000524 | 39.36 ms | loss 0.00307\n",
      "| epoch  32 |     6/    6 batches | lr 0.000524 | 11.69 ms | loss 0.00546\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time:  0.27s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  33 |     1/    6 batches | lr 0.000513 | 87.75 ms | loss 0.00702\n",
      "| epoch  33 |     2/    6 batches | lr 0.000513 | 39.35 ms | loss 0.00405\n",
      "| epoch  33 |     3/    6 batches | lr 0.000513 | 39.44 ms | loss 0.00310\n",
      "| epoch  33 |     4/    6 batches | lr 0.000513 | 39.45 ms | loss 0.00200\n",
      "| epoch  33 |     5/    6 batches | lr 0.000513 | 44.00 ms | loss 0.00330\n",
      "| epoch  33 |     6/    6 batches | lr 0.000513 | 11.75 ms | loss 0.00452\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  34 |     1/    6 batches | lr 0.000503 | 88.69 ms | loss 0.00622\n",
      "| epoch  34 |     2/    6 batches | lr 0.000503 | 39.32 ms | loss 0.00354\n",
      "| epoch  34 |     3/    6 batches | lr 0.000503 | 39.34 ms | loss 0.00294\n",
      "| epoch  34 |     4/    6 batches | lr 0.000503 | 39.38 ms | loss 0.00294\n",
      "| epoch  34 |     5/    6 batches | lr 0.000503 | 39.66 ms | loss 0.00364\n",
      "| epoch  34 |     6/    6 batches | lr 0.000503 | 11.75 ms | loss 0.00345\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  35 |     1/    6 batches | lr 0.000493 | 82.77 ms | loss 0.00544\n",
      "| epoch  35 |     2/    6 batches | lr 0.000493 | 39.42 ms | loss 0.00322\n",
      "| epoch  35 |     3/    6 batches | lr 0.000493 | 39.34 ms | loss 0.00340\n",
      "| epoch  35 |     4/    6 batches | lr 0.000493 | 39.44 ms | loss 0.00292\n",
      "| epoch  35 |     5/    6 batches | lr 0.000493 | 39.39 ms | loss 0.00260\n",
      "| epoch  35 |     6/    6 batches | lr 0.000493 | 11.71 ms | loss 0.00425\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time:  0.25s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  36 |     1/    6 batches | lr 0.000483 | 84.21 ms | loss 0.00671\n",
      "| epoch  36 |     2/    6 batches | lr 0.000483 | 39.37 ms | loss 0.00309\n",
      "| epoch  36 |     3/    6 batches | lr 0.000483 | 46.94 ms | loss 0.00373\n",
      "| epoch  36 |     4/    6 batches | lr 0.000483 | 43.47 ms | loss 0.00314\n",
      "| epoch  36 |     5/    6 batches | lr 0.000483 | 39.40 ms | loss 0.00212\n",
      "| epoch  36 |     6/    6 batches | lr 0.000483 | 11.70 ms | loss 0.00300\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time:  0.27s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  37 |     1/    6 batches | lr 0.000474 | 88.73 ms | loss 0.00546\n",
      "| epoch  37 |     2/    6 batches | lr 0.000474 | 39.32 ms | loss 0.00307\n",
      "| epoch  37 |     3/    6 batches | lr 0.000474 | 43.24 ms | loss 0.00262\n",
      "| epoch  37 |     4/    6 batches | lr 0.000474 | 39.37 ms | loss 0.00335\n",
      "| epoch  37 |     5/    6 batches | lr 0.000474 | 39.42 ms | loss 0.00258\n",
      "| epoch  37 |     6/    6 batches | lr 0.000474 | 11.72 ms | loss 0.00200\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  38 |     1/    6 batches | lr 0.000464 | 83.40 ms | loss 0.00507\n",
      "| epoch  38 |     2/    6 batches | lr 0.000464 | 39.77 ms | loss 0.00334\n",
      "| epoch  38 |     3/    6 batches | lr 0.000464 | 39.46 ms | loss 0.00217\n",
      "| epoch  38 |     4/    6 batches | lr 0.000464 | 39.37 ms | loss 0.00252\n",
      "| epoch  38 |     5/    6 batches | lr 0.000464 | 39.63 ms | loss 0.00299\n",
      "| epoch  38 |     6/    6 batches | lr 0.000464 | 11.73 ms | loss 0.00144\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  39 |     1/    6 batches | lr 0.000455 | 83.99 ms | loss 0.00471\n",
      "| epoch  39 |     2/    6 batches | lr 0.000455 | 39.40 ms | loss 0.00240\n",
      "| epoch  39 |     3/    6 batches | lr 0.000455 | 39.40 ms | loss 0.00198\n",
      "| epoch  39 |     4/    6 batches | lr 0.000455 | 39.45 ms | loss 0.00237\n",
      "| epoch  39 |     5/    6 batches | lr 0.000455 | 39.45 ms | loss 0.00361\n",
      "| epoch  39 |     6/    6 batches | lr 0.000455 | 11.69 ms | loss 0.00108\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time:  0.26s |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |     1/    6 batches | lr 0.000446 | 87.02 ms | loss 0.00440\n",
      "| epoch  40 |     2/    6 batches | lr 0.000446 | 42.64 ms | loss 0.00345\n",
      "| epoch  40 |     3/    6 batches | lr 0.000446 | 40.25 ms | loss 0.00243\n",
      "| epoch  40 |     4/    6 batches | lr 0.000446 | 39.40 ms | loss 0.00238\n",
      "| epoch  40 |     5/    6 batches | lr 0.000446 | 40.17 ms | loss 0.00225\n",
      "| epoch  40 |     6/    6 batches | lr 0.000446 | 13.74 ms | loss 0.00214\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time:  0.27s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-03)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
    "loss, acc =  train(model, 40, batch_size, train_loader, criterion,\n",
    "      optimizer, scheduler, set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee9f5e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff4718fdb50>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0973b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff44eda2940>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e098fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = torch.tensor([]).to(device)\n",
    "ground_truth = torch.tensor([]).to(device)\n",
    "for batch in test_loader:\n",
    "    data, targets = batch[0], batch[1] # next(iter(test_loader))\n",
    "    data = Variable(torch.Tensor(data.float())).to(device)\n",
    "    targets = Variable(torch.Tensor(targets.float())).to(device)\n",
    "    output = model(data)\n",
    "    loss = criterion(output, torch.flatten(targets.long()))\n",
    "\n",
    "predictions = torch.cat((predictions, output), 0)\n",
    "ground_truth = torch.cat((ground_truth, targets), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e489c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.cpu().detach().numpy()\n",
    "predictions = np.argmax(predictions, axis=1).reshape(predictions.shape[0], 1)\n",
    "ground_truth = ground_truth.cpu().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31efff9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mtx = confusion_matrix(ground_truth, predictions)\n",
    "\n",
    "conf_df = pd.DataFrame(conf_mtx, index = [i for i in range(5)],\n",
    "                  columns = [i for i in range(5)])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(conf_df, cmap=sns.cm.rocket_r, square=True, linewidths=0.1, annot=True, fmt='d', annot_kws={\"fontsize\": 8})  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9690803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Acc:\t 0.520\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(ground_truth, predictions)\n",
    "print(f' Acc:\\t {acc:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
