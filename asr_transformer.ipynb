{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62ac3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from transformer.model import TransformerTimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bb6f9",
   "metadata": {},
   "source": [
    "### Automatic speach recognition with neural networks\n",
    "This notebook uses MFCC pre-prossesing to generate acoustic features to the neural network, and then the neural network can be trained and tested. The baseline consists into HNNs. \n",
    "\n",
    "The dataset utilized in this notebook is the speach commands datasets from tensorflow. As this dataset comes with a lot of words and a lots of examples, we choose to simplify this notebook example by focusing in the following words: cat, dog, happy, house and zero. The training set consists into 25 examples of each word, and the testing set consists into 5 new examples of each word.\n",
    "\n",
    "All the pre-prossecing is made by the spock: . Using this software the user can process WAV files and output the processed acoustic features in `.FEA` files. Then the neural network can receive this accoustic features and output the class that corresponds to the right word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895ab5d",
   "metadata": {},
   "source": [
    "### The first step consists into reading the FEA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a64780",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dir = './output_100_25/mfcceda39w240s80/features'\n",
    "val_dir = './output_25_5/mfcceda39w240s80/features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c935d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1a3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fea_to_samples(filename):\n",
    "    # Discard the header with 2048 bytes that yield 512 floats\n",
    "    feat_array = np.fromfile(filename, dtype='>f') [512:]\n",
    "    num_of_paterns = feat_array[0]\n",
    "    space_dimension = feat_array[1]\n",
    "    \n",
    "    res = []\n",
    "    # Jump the first 2 floats\n",
    "    i_s = 2\n",
    "    total_frames = []\n",
    "    for pat in range(int(num_of_paterns)):\n",
    "        # Feature Extraction\n",
    "        n_frames = feat_array[i_s]\n",
    "        total_frames.append(n_frames) \n",
    "        i_e = space_dimension*n_frames + i_s + 1  \n",
    "        feat = feat_array[i_s+1: int(i_e)].tolist()\n",
    "        i_s = int(i_e)\n",
    "        res.append(feat)\n",
    "    \n",
    "    assert(i_e == len(feat_array))\n",
    "    \n",
    "    # Convert the feature patterns to a np matrix, padding according \n",
    "    # to the biggest entry\n",
    "    max_dim = max([len(row) for row in res])\n",
    "    res_np = np.zeros((int(num_of_paterns), max_dim))\n",
    "    \n",
    "    for pat in range(int(num_of_paterns)):\n",
    "        vec_len = len(res[pat])\n",
    "        res_np[pat][:vec_len] = res[pat] \n",
    "    \n",
    "    return res_np,(max(total_frames), space_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e332db",
   "metadata": {},
   "source": [
    "### After reading the FEA files we can organize the network input and desireble output\n",
    "In this supervised learning probblem we must organize matrices that will serve as input or features, and other that will be the desired output or label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a122ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xy_matrices(feat_dir):\n",
    "    files = listdir(feat_dir)\n",
    "    labels = [name[2:-4] for name in listdir(feat_dir)]\n",
    "    x_matrix, shape = fea_to_samples(feat_dir+ '/' +files[0])\n",
    "\n",
    "    y_matrix = np.zeros((x_matrix.shape[0], 1))\n",
    "    y_matrix[:,0] = 0\n",
    "    for file_i in range(1,len(files)):\n",
    "        x_i, _ = fea_to_samples(feat_dir + '/' + files[file_i])\n",
    "        y_i = np.zeros((x_i.shape[0], 1))\n",
    "        y_i[:,0] = file_i\n",
    "        x_matrix = np.concatenate((x_matrix, x_i))\n",
    "        y_matrix = np.concatenate((y_matrix, y_i))\n",
    "\n",
    "    return x_matrix, y_matrix, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601faacd",
   "metadata": {},
   "source": [
    "### After that we must organize our dataset object\n",
    "As we are using the Pytorch stack, it is recommended to use the Dataset class to organize the entry and output samples of training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6329e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MfcSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 x_matrix,\n",
    "                 y_matrix,\n",
    "                 shape,\n",
    "                std_scaler=None,\n",
    "                min_max_scaler=None):\n",
    "        \n",
    "#         if std_scaler==None:\n",
    "#             # Standard scaling\n",
    "#             std_scaler = StandardScaler()\n",
    "#             std_scaler.fit(x_matrix)\n",
    "#         x_matrix = std_scaler.transform(x_matrix)\n",
    "#         print(x_matrix.shape)\n",
    "       \n",
    "        if min_max_scaler == None:\n",
    "            # Min max scaling\n",
    "            min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "            min_max_scaler.fit(x_matrix)\n",
    "        x_matrix = min_max_scaler.transform(x_matrix)\n",
    "        \n",
    "        shape = (int(shape[0]), int(shape[1]))\n",
    "        self.X = x_matrix.reshape((x_matrix.shape[0], shape[0], shape[1]))\n",
    "        self.y = y_matrix\n",
    "        self.std_scaler = std_scaler\n",
    "        self.min_max_scaler = min_max_scaler\n",
    "        self.x_shape = self.X.shape\n",
    "        self.y_shape = self.y.shape\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b5a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(root_dir):\n",
    "    x_train, y_train, shape = generate_xy_matrices(root_dir + '/train')\n",
    "    x_test, y_test, _ = generate_xy_matrices(root_dir + '/test')\n",
    "    feat_scaler = MinMaxScaler()\n",
    "    feat_scaler.fit(x_train)\n",
    "    \n",
    "    train_set = MfcSet(x_train, y_train, shape)\n",
    "    test_set = MfcSet(x_test, y_test, shape, train_set.std_scaler, train_set.min_max_scaler)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1f530",
   "metadata": {},
   "source": [
    "### The multi layer perceptron network\n",
    "In this classification task, is desireble that we use a softmax activation function in the output layer, but as we are using the Pytorch stack, the loss function `CrossEntropyLoss` already apply the softmax for us. Then this is not necessary, as shown in the example bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7683b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "seed_torch()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "print(input.shape)\n",
    "print(target.shape)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c78c870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6502,  0.2096, -0.1404, -0.3335,  1.2450],\n",
       "        [ 0.3478, -0.6194,  0.1419, -1.3145,  0.2411],\n",
       "        [-0.1828,  0.0452, -1.7188,  0.1175, -0.5912]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ecc0a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31eff65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, batch_size, train_loader, criterion, optimizer,\n",
    "          scheduler, set_size, val_loader):\n",
    "    model.train()\n",
    "    acc = []\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_loss, train_acc = batch_train(model, epoch, batch_size,\n",
    "                                                train_loader, criterion,\n",
    "                                                optimizer, scheduler, set_size)\n",
    "\n",
    "        epoch_val_loss, epoch_val_acc = batch_val(model, epoch, batch_size, val_loader)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s |'.format(\n",
    "            epoch, (time.time() - epoch_start_time)))\n",
    "        print('-' * 89)\n",
    "\n",
    "        scheduler.step()\n",
    "        acc.append(train_acc)\n",
    "        loss.append(train_loss)\n",
    "        val_acc.append(epoch_val_acc)\n",
    "        val_loss.append(epoch_val_loss)\n",
    "    return loss, val_loss, acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36497111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(model, epoch, batch_size, val_loader, criterion, optimizer,\n",
    "                scheduler, set_size):\n",
    "    model.train()  # Turn on the train mode\n",
    "    batch_loss = 0.\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    predictions = torch.tensor([]).to(device)\n",
    "    ground_truth = torch.tensor([]).to(device)\n",
    "\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        data, targets = batch[0], batch[1]\n",
    "        data = Variable(torch.Tensor(data.float())).to(device)\n",
    "        targets = Variable(torch.Tensor(targets.float())).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, torch.flatten(targets.long()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "        total_loss += batch_loss\n",
    "        log_interval = int(set_size / batch_size / 5)\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            cur_loss = batch_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.6f} | {:5.2f} ms | '\n",
    "                  'loss {:5.5f}'.format(epoch, i, set_size // batch_size,\n",
    "                                        scheduler.get_lr()[0],\n",
    "                                        elapsed * 1000 / log_interval,\n",
    "                                        cur_loss))\n",
    "            batch_loss = 0\n",
    "            start_time = time.time()\n",
    "        pred = output\n",
    "        predictions = torch.cat((predictions, pred), 0)\n",
    "        ground_truth = torch.cat((ground_truth, targets), 0)\n",
    "        \n",
    "\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    predictions = np.argmax(predictions, axis=1).reshape(predictions.shape[0], 1)\n",
    "    ground_truth = ground_truth.cpu().cpu().detach().numpy()\n",
    "    acc = accuracy_score(ground_truth, predictions)\n",
    "    return total_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c51ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_val(model, epoch, batch_size, train_loader):\n",
    "    model.eval()  # Turn on the train mode\n",
    "    batch_loss = 0.\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    predictions = torch.tensor([]).to(device)\n",
    "    ground_truth = torch.tensor([]).to(device)\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        data, targets = batch[0], batch[1]\n",
    "        data = Variable(torch.Tensor(data.float())).to(device)\n",
    "        targets = Variable(torch.Tensor(targets.float())).to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, torch.flatten(targets.long()))\n",
    "        batch_loss += loss.item()\n",
    "        total_loss += batch_loss\n",
    "        pred = output\n",
    "        predictions = torch.cat((predictions, pred), 0)\n",
    "        ground_truth = torch.cat((ground_truth, targets), 0)\n",
    "        \n",
    "\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    predictions = np.argmax(predictions, axis=1).reshape(predictions.shape[0], 1)\n",
    "    ground_truth = ground_truth.cpu().cpu().detach().numpy()\n",
    "    acc = accuracy_score(ground_truth, predictions)\n",
    "    return total_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a925ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "\n",
    "train_set, test_set = build_dataset(feat_dir)\n",
    "_, val_set = build_dataset(val_dir)\n",
    "\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_set,\n",
    "                          batch_size=test_set.y_shape[0],\n",
    "                          shuffle=False)\n",
    "set_size = train_set.y_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c84b6f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 197, 39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.x_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513801dc",
   "metadata": {},
   "source": [
    "### One example of feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6ed9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat, label = next(iter(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f43d8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [max(row) for row in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc199d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5917579142574786,\n",
       " 0.5560038487216199,\n",
       " 0.5511293476023874,\n",
       " 0.49870560577016654,\n",
       " 0.39811523374353885,\n",
       " 0.4712425714621693,\n",
       " 0.4892133434535489,\n",
       " 0.4821444060280947,\n",
       " 0.5907853579249047,\n",
       " 0.4994273167736055,\n",
       " 0.6154428299435482,\n",
       " 0.5554048354093615,\n",
       " 0.4096236194799816,\n",
       " 0.572527940808141,\n",
       " 0.41651383718388113,\n",
       " 0.4497101183865286,\n",
       " 0.41346418648444283,\n",
       " 0.3413565208009973,\n",
       " 0.3840450555129067,\n",
       " 0.36070213203960116,\n",
       " 0.3060755880974882,\n",
       " 0.3887421753882147,\n",
       " 0.3497475126002845,\n",
       " 0.3887372697738767,\n",
       " 0.5551703968792738,\n",
       " 0.8383767912994942,\n",
       " 1.0000000000000002,\n",
       " 0.9161812057900246,\n",
       " 0.9999999999999999,\n",
       " 0.7509248855004169,\n",
       " 0.7213933258153677,\n",
       " 0.8110500375248144,\n",
       " 0.6062274821629451,\n",
       " 0.8995768715260435,\n",
       " 1.0000000000000002,\n",
       " 0.7119945402655663,\n",
       " 0.8311148054548088,\n",
       " 0.8322261862315716,\n",
       " 0.7330115436119035,\n",
       " 0.8706316189584585,\n",
       " 0.823803130283401,\n",
       " 0.8500979536782285,\n",
       " 0.7525938661199923,\n",
       " 0.885953278641489,\n",
       " 0.9212822296770223,\n",
       " 0.8150729463260945,\n",
       " 0.8116606353614231,\n",
       " 0.594798216119505,\n",
       " 0.9044703673900452,\n",
       " 0.6581498079707736,\n",
       " 0.800541992624389,\n",
       " 0.873153270801378,\n",
       " 0.912313044908517,\n",
       " 0.8972314659934039,\n",
       " 0.8779007572642142,\n",
       " 0.869215290318181,\n",
       " 0.8686715814541385,\n",
       " 0.8846610349922297,\n",
       " 0.9315583299445368,\n",
       " 0.9780699259455533,\n",
       " 1.0,\n",
       " 0.9879017270819913,\n",
       " 0.948551432253116,\n",
       " 0.9328754079774108,\n",
       " 0.9228603341901719,\n",
       " 0.9206326913600419,\n",
       " 0.9020676895532661,\n",
       " 0.8850391752409729,\n",
       " 0.8767457253886867,\n",
       " 0.8769935058708146,\n",
       " 0.8880149225355302,\n",
       " 0.8964024937661089,\n",
       " 0.8765439183850646,\n",
       " 0.88532340316552,\n",
       " 0.9117922192398568,\n",
       " 0.9434855483884647,\n",
       " 0.9426654809340337,\n",
       " 0.9234448393391951,\n",
       " 0.8840825334213406,\n",
       " 0.8213936572674848,\n",
       " 0.7571510017927715,\n",
       " 0.7410644260704985,\n",
       " 0.7466087861607716,\n",
       " 0.7706136722924771,\n",
       " 0.7413430626260381,\n",
       " 0.7037585014209521,\n",
       " 0.5713959902403173,\n",
       " 0.6282810141277158,\n",
       " 0.5799627333546504,\n",
       " 0.4439740654227096,\n",
       " 0.5799626903526012,\n",
       " 0.7625487967103047,\n",
       " 0.7199064640003732,\n",
       " 0.6062952163395187,\n",
       " 0.7271213485563852,\n",
       " 0.6421982527517116,\n",
       " 0.7074305761599797,\n",
       " 0.8705814406521446,\n",
       " 0.7623576595583166,\n",
       " 0.6200169769280439,\n",
       " 0.8270131583382517,\n",
       " 0.764154799317324,\n",
       " 0.8744641220126007,\n",
       " 0.8448988353056479,\n",
       " 1.0,\n",
       " 0.9217592387517265,\n",
       " 0.9637966930385458,\n",
       " 0.8351415360819654,\n",
       " 0.9827333610996158,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9562405246715393,\n",
       " 0.872474956368408,\n",
       " 1.0,\n",
       " 0.7171888852722029,\n",
       " 0.65310330282717,\n",
       " 0.5636439754858134,\n",
       " 0.6634591820444184,\n",
       " 0.6817824899874425,\n",
       " 0.5654492896497596,\n",
       " 0.41937004438027664,\n",
       " 0.5736248161713446,\n",
       " 0.3818802533884316,\n",
       " 0.5722364470861925,\n",
       " 0.45610540202614896,\n",
       " 0.41672887132777325,\n",
       " 0.5456680632498063,\n",
       " 0.4931168611423034,\n",
       " 0.5822875076846354,\n",
       " 0.6155219658119357,\n",
       " 0.6529609058488235,\n",
       " 0.6481072374217876,\n",
       " 0.6846736797934255,\n",
       " 0.6746752824102868,\n",
       " 0.6077800546271914,\n",
       " 0.5431652657598368,\n",
       " 0.5745158681268157,\n",
       " 0.6671915611673958,\n",
       " 0.6104340216123435,\n",
       " 0.6046606817474025,\n",
       " 0.6694432702975978,\n",
       " 0.5782771870411115,\n",
       " 0.5953679120088361,\n",
       " 0.5386396969040004,\n",
       " 0.46165881487834964,\n",
       " 0.6802226668124532,\n",
       " 0.4976761442751514,\n",
       " 0.5868079873900576,\n",
       " 0.7736176944398626,\n",
       " 0.5002767742275813,\n",
       " 0.5330297096117692,\n",
       " 0.4868882607716612,\n",
       " 0.36281348303635136,\n",
       " 0.44651471604076615,\n",
       " 0.3983415898566752,\n",
       " 0.48312650367942955,\n",
       " 0.3340255635916566,\n",
       " 0.6831227587295804,\n",
       " 0.5897458978760075,\n",
       " 0.6888653198846728,\n",
       " 0.6545598615461354,\n",
       " 0.6576437779479046,\n",
       " 0.5193383477276776,\n",
       " 0.7566674618349359,\n",
       " 0.5149168191358997,\n",
       " 0.6648792197746731,\n",
       " 0.5115719950401403,\n",
       " 0.4366203189024409,\n",
       " 0.6089140976772834,\n",
       " 0.9119442457232765,\n",
       " 0.9999999999999999,\n",
       " 1.0,\n",
       " 1.0000000000000002,\n",
       " 1.0,\n",
       " 1.0000000000000002,\n",
       " 1.0,\n",
       " 0.9999999999999999,\n",
       " 1.0,\n",
       " 0.9999999999999999,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999998,\n",
       " 1.0,\n",
       " 0.8764551726433342,\n",
       " 0.9139517019120116,\n",
       " 0.8808122160927355,\n",
       " 0.9489472494546809,\n",
       " 0.9909043646682332,\n",
       " 0.7065044466735577,\n",
       " 0.7875536011026107,\n",
       " 0.925152580394608,\n",
       " 0.9734900240104581,\n",
       " 1.0,\n",
       " 0.9705949081623791,\n",
       " 0.8857333529465037]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d38eff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c92119d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TransformerTimeSeries(device,\n",
    "                              n_encoder_time_steps=197,\n",
    "                              encoder_vector_sz=39,\n",
    "                              output_vector_sz=5,\n",
    "                              d_model=220,\n",
    "                              dropout=0.3,\n",
    "                              nhead=4).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091de7e",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04cd47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     2/   12 batches | lr 0.001000 | 210.09 ms | loss 2.68826\n",
      "| epoch   1 |     4/   12 batches | lr 0.001000 | 134.68 ms | loss 1.65782\n",
      "| epoch   1 |     6/   12 batches | lr 0.001000 | 137.86 ms | loss 1.66070\n",
      "| epoch   1 |     8/   12 batches | lr 0.001000 | 152.07 ms | loss 1.67806\n",
      "| epoch   1 |    10/   12 batches | lr 0.001000 | 137.07 ms | loss 1.67575\n",
      "| epoch   1 |    12/   12 batches | lr 0.001000 | 95.20 ms | loss 1.62405\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  1.89s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |     2/   12 batches | lr 0.000960 | 198.14 ms | loss 2.46503\n",
      "| epoch   2 |     4/   12 batches | lr 0.000960 | 137.65 ms | loss 1.63826\n",
      "| epoch   2 |     6/   12 batches | lr 0.000960 | 136.04 ms | loss 1.59200\n",
      "| epoch   2 |     8/   12 batches | lr 0.000960 | 135.68 ms | loss 1.62890\n",
      "| epoch   2 |    10/   12 batches | lr 0.000960 | 134.93 ms | loss 1.65006\n",
      "| epoch   2 |    12/   12 batches | lr 0.000960 | 95.47 ms | loss 1.64931\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |     2/   12 batches | lr 0.000941 | 201.92 ms | loss 2.43945\n",
      "| epoch   3 |     4/   12 batches | lr 0.000941 | 144.46 ms | loss 1.65367\n",
      "| epoch   3 |     6/   12 batches | lr 0.000941 | 135.66 ms | loss 1.64024\n",
      "| epoch   3 |     8/   12 batches | lr 0.000941 | 139.85 ms | loss 1.60803\n",
      "| epoch   3 |    10/   12 batches | lr 0.000941 | 137.32 ms | loss 1.58367\n",
      "| epoch   3 |    12/   12 batches | lr 0.000941 | 97.71 ms | loss 1.62075\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.87s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |     2/   12 batches | lr 0.000922 | 198.91 ms | loss 2.38473\n",
      "| epoch   4 |     4/   12 batches | lr 0.000922 | 135.25 ms | loss 1.57661\n",
      "| epoch   4 |     6/   12 batches | lr 0.000922 | 137.75 ms | loss 1.60838\n",
      "| epoch   4 |     8/   12 batches | lr 0.000922 | 135.18 ms | loss 1.60911\n",
      "| epoch   4 |    10/   12 batches | lr 0.000922 | 139.23 ms | loss 1.60912\n",
      "| epoch   4 |    12/   12 batches | lr 0.000922 | 95.53 ms | loss 1.56377\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |     2/   12 batches | lr 0.000904 | 198.72 ms | loss 2.41185\n",
      "| epoch   5 |     4/   12 batches | lr 0.000904 | 143.76 ms | loss 1.60184\n",
      "| epoch   5 |     6/   12 batches | lr 0.000904 | 137.38 ms | loss 1.62422\n",
      "| epoch   5 |     8/   12 batches | lr 0.000904 | 138.58 ms | loss 1.60393\n",
      "| epoch   5 |    10/   12 batches | lr 0.000904 | 135.82 ms | loss 1.57420\n",
      "| epoch   5 |    12/   12 batches | lr 0.000904 | 98.82 ms | loss 1.56189\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.86s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |     2/   12 batches | lr 0.000886 | 201.76 ms | loss 2.38570\n",
      "| epoch   6 |     4/   12 batches | lr 0.000886 | 135.86 ms | loss 1.57382\n",
      "| epoch   6 |     6/   12 batches | lr 0.000886 | 140.37 ms | loss 1.57152\n",
      "| epoch   6 |     8/   12 batches | lr 0.000886 | 137.96 ms | loss 1.54335\n",
      "| epoch   6 |    10/   12 batches | lr 0.000886 | 135.60 ms | loss 1.52715\n",
      "| epoch   6 |    12/   12 batches | lr 0.000886 | 96.03 ms | loss 1.45928\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   7 |     2/   12 batches | lr 0.000868 | 203.93 ms | loss 2.26986\n",
      "| epoch   7 |     4/   12 batches | lr 0.000868 | 135.71 ms | loss 1.38851\n",
      "| epoch   7 |     6/   12 batches | lr 0.000868 | 135.96 ms | loss 1.73895\n",
      "| epoch   7 |     8/   12 batches | lr 0.000868 | 139.07 ms | loss 1.40204\n",
      "| epoch   7 |    10/   12 batches | lr 0.000868 | 135.56 ms | loss 1.40975\n",
      "| epoch   7 |    12/   12 batches | lr 0.000868 | 95.91 ms | loss 1.52515\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   8 |     2/   12 batches | lr 0.000851 | 206.74 ms | loss 2.28389\n",
      "| epoch   8 |     4/   12 batches | lr 0.000851 | 144.40 ms | loss 1.49147\n",
      "| epoch   8 |     6/   12 batches | lr 0.000851 | 135.90 ms | loss 1.49515\n",
      "| epoch   8 |     8/   12 batches | lr 0.000851 | 135.61 ms | loss 1.40519\n",
      "| epoch   8 |    10/   12 batches | lr 0.000851 | 138.11 ms | loss 1.39832\n",
      "| epoch   8 |    12/   12 batches | lr 0.000851 | 98.59 ms | loss 1.35698\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  1.87s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   9 |     2/   12 batches | lr 0.000834 | 211.82 ms | loss 1.95087\n",
      "| epoch   9 |     4/   12 batches | lr 0.000834 | 135.61 ms | loss 1.26418\n",
      "| epoch   9 |     6/   12 batches | lr 0.000834 | 134.44 ms | loss 1.19547\n",
      "| epoch   9 |     8/   12 batches | lr 0.000834 | 137.23 ms | loss 1.08753\n",
      "| epoch   9 |    10/   12 batches | lr 0.000834 | 134.62 ms | loss 1.16549\n",
      "| epoch   9 |    12/   12 batches | lr 0.000834 | 97.65 ms | loss 1.16315\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  10 |     2/   12 batches | lr 0.000817 | 198.25 ms | loss 1.70149\n",
      "| epoch  10 |     4/   12 batches | lr 0.000817 | 146.07 ms | loss 1.09693\n",
      "| epoch  10 |     6/   12 batches | lr 0.000817 | 135.62 ms | loss 1.10585\n",
      "| epoch  10 |     8/   12 batches | lr 0.000817 | 133.88 ms | loss 1.20445\n",
      "| epoch  10 |    10/   12 batches | lr 0.000817 | 134.07 ms | loss 1.19494\n",
      "| epoch  10 |    12/   12 batches | lr 0.000817 | 98.92 ms | loss 1.16197\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |     2/   12 batches | lr 0.000801 | 197.82 ms | loss 1.71351\n",
      "| epoch  11 |     4/   12 batches | lr 0.000801 | 150.88 ms | loss 1.14104\n",
      "| epoch  11 |     6/   12 batches | lr 0.000801 | 138.66 ms | loss 1.20136\n",
      "| epoch  11 |     8/   12 batches | lr 0.000801 | 134.05 ms | loss 0.96213\n",
      "| epoch  11 |    10/   12 batches | lr 0.000801 | 134.55 ms | loss 1.03716\n",
      "| epoch  11 |    12/   12 batches | lr 0.000801 | 99.16 ms | loss 0.89342\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  1.86s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |     2/   12 batches | lr 0.000785 | 200.18 ms | loss 1.37765\n",
      "| epoch  12 |     4/   12 batches | lr 0.000785 | 133.91 ms | loss 0.85145\n",
      "| epoch  12 |     6/   12 batches | lr 0.000785 | 134.14 ms | loss 0.94429\n",
      "| epoch  12 |     8/   12 batches | lr 0.000785 | 137.48 ms | loss 0.87577\n",
      "| epoch  12 |    10/   12 batches | lr 0.000785 | 134.18 ms | loss 0.90715\n",
      "| epoch  12 |    12/   12 batches | lr 0.000785 | 98.94 ms | loss 0.94689\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |     2/   12 batches | lr 0.000769 | 201.14 ms | loss 1.33932\n",
      "| epoch  13 |     4/   12 batches | lr 0.000769 | 134.04 ms | loss 0.94253\n",
      "| epoch  13 |     6/   12 batches | lr 0.000769 | 134.19 ms | loss 0.85981\n",
      "| epoch  13 |     8/   12 batches | lr 0.000769 | 140.22 ms | loss 0.90176\n",
      "| epoch  13 |    10/   12 batches | lr 0.000769 | 134.91 ms | loss 0.95457\n",
      "| epoch  13 |    12/   12 batches | lr 0.000769 | 95.79 ms | loss 0.85345\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 |     2/   12 batches | lr 0.000754 | 200.09 ms | loss 1.45228\n",
      "| epoch  14 |     4/   12 batches | lr 0.000754 | 134.06 ms | loss 0.80983\n",
      "| epoch  14 |     6/   12 batches | lr 0.000754 | 133.85 ms | loss 0.84961\n",
      "| epoch  14 |     8/   12 batches | lr 0.000754 | 136.68 ms | loss 0.78867\n",
      "| epoch  14 |    10/   12 batches | lr 0.000754 | 138.15 ms | loss 0.82316\n",
      "| epoch  14 |    12/   12 batches | lr 0.000754 | 96.13 ms | loss 0.93873\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  15 |     2/   12 batches | lr 0.000739 | 198.02 ms | loss 1.44200\n",
      "| epoch  15 |     4/   12 batches | lr 0.000739 | 146.48 ms | loss 0.88626\n",
      "| epoch  15 |     6/   12 batches | lr 0.000739 | 134.35 ms | loss 0.94582\n",
      "| epoch  15 |     8/   12 batches | lr 0.000739 | 134.44 ms | loss 0.73137\n",
      "| epoch  15 |    10/   12 batches | lr 0.000739 | 137.18 ms | loss 0.90351\n",
      "| epoch  15 |    12/   12 batches | lr 0.000739 | 97.41 ms | loss 0.73617\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  16 |     2/   12 batches | lr 0.000724 | 201.19 ms | loss 1.04642\n",
      "| epoch  16 |     4/   12 batches | lr 0.000724 | 142.52 ms | loss 0.75094\n",
      "| epoch  16 |     6/   12 batches | lr 0.000724 | 134.51 ms | loss 0.73780\n",
      "| epoch  16 |     8/   12 batches | lr 0.000724 | 134.97 ms | loss 0.77312\n",
      "| epoch  16 |    10/   12 batches | lr 0.000724 | 134.57 ms | loss 0.66719\n",
      "| epoch  16 |    12/   12 batches | lr 0.000724 | 99.50 ms | loss 0.73211\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  1.86s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  17 |     2/   12 batches | lr 0.000709 | 200.01 ms | loss 1.04496\n",
      "| epoch  17 |     4/   12 batches | lr 0.000709 | 140.90 ms | loss 0.73362\n",
      "| epoch  17 |     6/   12 batches | lr 0.000709 | 138.00 ms | loss 0.75232\n",
      "| epoch  17 |     8/   12 batches | lr 0.000709 | 134.57 ms | loss 0.65515\n",
      "| epoch  17 |    10/   12 batches | lr 0.000709 | 136.95 ms | loss 0.78168\n",
      "| epoch  17 |    12/   12 batches | lr 0.000709 | 96.24 ms | loss 0.61987\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  18 |     2/   12 batches | lr 0.000695 | 202.10 ms | loss 1.03148\n",
      "| epoch  18 |     4/   12 batches | lr 0.000695 | 141.45 ms | loss 0.53977\n",
      "| epoch  18 |     6/   12 batches | lr 0.000695 | 134.99 ms | loss 0.69718\n",
      "| epoch  18 |     8/   12 batches | lr 0.000695 | 137.95 ms | loss 0.74700\n",
      "| epoch  18 |    10/   12 batches | lr 0.000695 | 137.02 ms | loss 0.63354\n",
      "| epoch  18 |    12/   12 batches | lr 0.000695 | 96.24 ms | loss 0.64957\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  19 |     2/   12 batches | lr 0.000681 | 200.80 ms | loss 0.83498\n",
      "| epoch  19 |     4/   12 batches | lr 0.000681 | 146.28 ms | loss 0.72325\n",
      "| epoch  19 |     6/   12 batches | lr 0.000681 | 136.94 ms | loss 0.62750\n",
      "| epoch  19 |     8/   12 batches | lr 0.000681 | 137.76 ms | loss 0.45680\n",
      "| epoch  19 |    10/   12 batches | lr 0.000681 | 134.40 ms | loss 0.53511\n",
      "| epoch  19 |    12/   12 batches | lr 0.000681 | 96.12 ms | loss 0.64978\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  20 |     2/   12 batches | lr 0.000668 | 205.93 ms | loss 0.93637\n",
      "| epoch  20 |     4/   12 batches | lr 0.000668 | 141.59 ms | loss 0.48840\n",
      "| epoch  20 |     6/   12 batches | lr 0.000668 | 135.15 ms | loss 0.42610\n",
      "| epoch  20 |     8/   12 batches | lr 0.000668 | 137.41 ms | loss 0.51449\n",
      "| epoch  20 |    10/   12 batches | lr 0.000668 | 135.15 ms | loss 0.59389\n",
      "| epoch  20 |    12/   12 batches | lr 0.000668 | 96.18 ms | loss 0.58621\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  21 |     2/   12 batches | lr 0.000654 | 203.48 ms | loss 0.96847\n",
      "| epoch  21 |     4/   12 batches | lr 0.000654 | 141.79 ms | loss 0.56874\n",
      "| epoch  21 |     6/   12 batches | lr 0.000654 | 141.70 ms | loss 0.46004\n",
      "| epoch  21 |     8/   12 batches | lr 0.000654 | 134.83 ms | loss 0.53638\n",
      "| epoch  21 |    10/   12 batches | lr 0.000654 | 137.08 ms | loss 0.50028\n",
      "| epoch  21 |    12/   12 batches | lr 0.000654 | 98.95 ms | loss 0.71893\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  1.87s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  22 |     2/   12 batches | lr 0.000641 | 197.95 ms | loss 0.78541\n",
      "| epoch  22 |     4/   12 batches | lr 0.000641 | 137.39 ms | loss 0.49970\n",
      "| epoch  22 |     6/   12 batches | lr 0.000641 | 135.26 ms | loss 0.42530\n",
      "| epoch  22 |     8/   12 batches | lr 0.000641 | 137.66 ms | loss 0.63524\n",
      "| epoch  22 |    10/   12 batches | lr 0.000641 | 138.54 ms | loss 0.63437\n",
      "| epoch  22 |    12/   12 batches | lr 0.000641 | 98.90 ms | loss 0.39809\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  23 |     2/   12 batches | lr 0.000628 | 198.96 ms | loss 0.78808\n",
      "| epoch  23 |     4/   12 batches | lr 0.000628 | 137.07 ms | loss 0.52408\n",
      "| epoch  23 |     6/   12 batches | lr 0.000628 | 136.80 ms | loss 0.54190\n",
      "| epoch  23 |     8/   12 batches | lr 0.000628 | 134.58 ms | loss 0.42276\n",
      "| epoch  23 |    10/   12 batches | lr 0.000628 | 138.87 ms | loss 0.52216\n",
      "| epoch  23 |    12/   12 batches | lr 0.000628 | 98.68 ms | loss 0.53196\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  24 |     2/   12 batches | lr 0.000616 | 198.24 ms | loss 0.96959\n",
      "| epoch  24 |     4/   12 batches | lr 0.000616 | 156.44 ms | loss 0.40451\n",
      "| epoch  24 |     6/   12 batches | lr 0.000616 | 261.74 ms | loss 0.54615\n",
      "| epoch  24 |     8/   12 batches | lr 0.000616 | 138.85 ms | loss 0.48391\n",
      "| epoch  24 |    10/   12 batches | lr 0.000616 | 210.76 ms | loss 0.44088\n",
      "| epoch  24 |    12/   12 batches | lr 0.000616 | 207.29 ms | loss 0.33228\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  2.58s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  25 |     2/   12 batches | lr 0.000603 | 222.45 ms | loss 0.53611\n",
      "| epoch  25 |     4/   12 batches | lr 0.000603 | 146.61 ms | loss 0.67542\n",
      "| epoch  25 |     6/   12 batches | lr 0.000603 | 405.21 ms | loss 0.55163\n",
      "| epoch  25 |     8/   12 batches | lr 0.000603 | 151.70 ms | loss 0.28050\n",
      "| epoch  25 |    10/   12 batches | lr 0.000603 | 138.31 ms | loss 0.35922\n",
      "| epoch  25 |    12/   12 batches | lr 0.000603 | 99.69 ms | loss 0.43303\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  2.49s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  26 |     2/   12 batches | lr 0.000591 | 198.95 ms | loss 0.63527\n",
      "| epoch  26 |     4/   12 batches | lr 0.000591 | 137.29 ms | loss 0.44424\n",
      "| epoch  26 |     6/   12 batches | lr 0.000591 | 137.11 ms | loss 0.46866\n",
      "| epoch  26 |     8/   12 batches | lr 0.000591 | 137.33 ms | loss 0.44663\n",
      "| epoch  26 |    10/   12 batches | lr 0.000591 | 136.95 ms | loss 0.47317\n",
      "| epoch  26 |    12/   12 batches | lr 0.000591 | 96.21 ms | loss 0.39968\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  27 |     2/   12 batches | lr 0.000580 | 198.93 ms | loss 0.68790\n",
      "| epoch  27 |     4/   12 batches | lr 0.000580 | 140.81 ms | loss 0.42412\n",
      "| epoch  27 |     6/   12 batches | lr 0.000580 | 138.71 ms | loss 0.19589\n",
      "| epoch  27 |     8/   12 batches | lr 0.000580 | 138.76 ms | loss 0.52724\n",
      "| epoch  27 |    10/   12 batches | lr 0.000580 | 134.73 ms | loss 0.46643\n",
      "| epoch  27 |    12/   12 batches | lr 0.000580 | 96.26 ms | loss 0.27829\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  28 |     2/   12 batches | lr 0.000568 | 201.33 ms | loss 0.61730\n",
      "| epoch  28 |     4/   12 batches | lr 0.000568 | 135.12 ms | loss 0.37505\n",
      "| epoch  28 |     6/   12 batches | lr 0.000568 | 138.18 ms | loss 0.30923\n",
      "| epoch  28 |     8/   12 batches | lr 0.000568 | 139.29 ms | loss 0.41213\n",
      "| epoch  28 |    10/   12 batches | lr 0.000568 | 134.50 ms | loss 0.28077\n",
      "| epoch  28 |    12/   12 batches | lr 0.000568 | 96.34 ms | loss 0.17571\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  29 |     2/   12 batches | lr 0.000557 | 200.24 ms | loss 0.51225\n",
      "| epoch  29 |     4/   12 batches | lr 0.000557 | 135.06 ms | loss 0.33799\n",
      "| epoch  29 |     6/   12 batches | lr 0.000557 | 134.93 ms | loss 0.39976\n",
      "| epoch  29 |     8/   12 batches | lr 0.000557 | 134.66 ms | loss 0.29514\n",
      "| epoch  29 |    10/   12 batches | lr 0.000557 | 138.33 ms | loss 0.30390\n",
      "| epoch  29 |    12/   12 batches | lr 0.000557 | 96.16 ms | loss 0.27079\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  30 |     2/   12 batches | lr 0.000545 | 205.18 ms | loss 0.39502\n",
      "| epoch  30 |     4/   12 batches | lr 0.000545 | 134.68 ms | loss 0.34042\n",
      "| epoch  30 |     6/   12 batches | lr 0.000545 | 134.30 ms | loss 0.32784\n",
      "| epoch  30 |     8/   12 batches | lr 0.000545 | 135.14 ms | loss 0.21855\n",
      "| epoch  30 |    10/   12 batches | lr 0.000545 | 140.35 ms | loss 0.24904\n",
      "| epoch  30 |    12/   12 batches | lr 0.000545 | 97.42 ms | loss 0.49358\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  31 |     2/   12 batches | lr 0.000535 | 197.96 ms | loss 0.23571\n",
      "| epoch  31 |     4/   12 batches | lr 0.000535 | 136.97 ms | loss 0.32321\n",
      "| epoch  31 |     6/   12 batches | lr 0.000535 | 134.51 ms | loss 0.38631\n",
      "| epoch  31 |     8/   12 batches | lr 0.000535 | 134.47 ms | loss 0.30949\n",
      "| epoch  31 |    10/   12 batches | lr 0.000535 | 137.08 ms | loss 0.47195\n",
      "| epoch  31 |    12/   12 batches | lr 0.000535 | 98.76 ms | loss 0.30010\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  32 |     2/   12 batches | lr 0.000524 | 198.22 ms | loss 0.36689\n",
      "| epoch  32 |     4/   12 batches | lr 0.000524 | 134.46 ms | loss 0.28666\n",
      "| epoch  32 |     6/   12 batches | lr 0.000524 | 137.19 ms | loss 0.23572\n",
      "| epoch  32 |     8/   12 batches | lr 0.000524 | 134.58 ms | loss 0.40311\n",
      "| epoch  32 |    10/   12 batches | lr 0.000524 | 134.44 ms | loss 0.20509\n",
      "| epoch  32 |    12/   12 batches | lr 0.000524 | 99.59 ms | loss 0.20334\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  33 |     2/   12 batches | lr 0.000513 | 199.64 ms | loss 0.29932\n",
      "| epoch  33 |     4/   12 batches | lr 0.000513 | 136.87 ms | loss 0.22481\n",
      "| epoch  33 |     6/   12 batches | lr 0.000513 | 137.01 ms | loss 0.14640\n",
      "| epoch  33 |     8/   12 batches | lr 0.000513 | 134.41 ms | loss 0.19282\n",
      "| epoch  33 |    10/   12 batches | lr 0.000513 | 135.07 ms | loss 0.37547\n",
      "| epoch  33 |    12/   12 batches | lr 0.000513 | 96.24 ms | loss 0.17132\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  34 |     2/   12 batches | lr 0.000503 | 204.92 ms | loss 0.25839\n",
      "| epoch  34 |     4/   12 batches | lr 0.000503 | 141.42 ms | loss 0.17463\n",
      "| epoch  34 |     6/   12 batches | lr 0.000503 | 134.42 ms | loss 0.26955\n",
      "| epoch  34 |     8/   12 batches | lr 0.000503 | 137.54 ms | loss 0.18077\n",
      "| epoch  34 |    10/   12 batches | lr 0.000503 | 134.63 ms | loss 0.27106\n",
      "| epoch  34 |    12/   12 batches | lr 0.000503 | 96.41 ms | loss 0.15914\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  35 |     2/   12 batches | lr 0.000493 | 199.88 ms | loss 0.22459\n",
      "| epoch  35 |     4/   12 batches | lr 0.000493 | 144.12 ms | loss 0.23231\n",
      "| epoch  35 |     6/   12 batches | lr 0.000493 | 134.94 ms | loss 0.15442\n",
      "| epoch  35 |     8/   12 batches | lr 0.000493 | 140.00 ms | loss 0.22701\n",
      "| epoch  35 |    10/   12 batches | lr 0.000493 | 135.57 ms | loss 0.17033\n",
      "| epoch  35 |    12/   12 batches | lr 0.000493 | 96.19 ms | loss 0.11985\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  36 |     2/   12 batches | lr 0.000483 | 200.57 ms | loss 0.26753\n",
      "| epoch  36 |     4/   12 batches | lr 0.000483 | 141.96 ms | loss 0.15572\n",
      "| epoch  36 |     6/   12 batches | lr 0.000483 | 142.36 ms | loss 0.24555\n",
      "| epoch  36 |     8/   12 batches | lr 0.000483 | 137.44 ms | loss 0.16330\n",
      "| epoch  36 |    10/   12 batches | lr 0.000483 | 137.74 ms | loss 0.21124\n",
      "| epoch  36 |    12/   12 batches | lr 0.000483 | 96.17 ms | loss 0.17561\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time:  1.86s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  37 |     2/   12 batches | lr 0.000474 | 198.21 ms | loss 0.26076\n",
      "| epoch  37 |     4/   12 batches | lr 0.000474 | 146.87 ms | loss 0.10029\n",
      "| epoch  37 |     6/   12 batches | lr 0.000474 | 136.85 ms | loss 0.26127\n",
      "| epoch  37 |     8/   12 batches | lr 0.000474 | 135.23 ms | loss 0.15618\n",
      "| epoch  37 |    10/   12 batches | lr 0.000474 | 136.36 ms | loss 0.17132\n",
      "| epoch  37 |    12/   12 batches | lr 0.000474 | 96.79 ms | loss 0.09865\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  38 |     2/   12 batches | lr 0.000464 | 200.87 ms | loss 0.29739\n",
      "| epoch  38 |     4/   12 batches | lr 0.000464 | 138.53 ms | loss 0.16208\n",
      "| epoch  38 |     6/   12 batches | lr 0.000464 | 135.54 ms | loss 0.28763\n",
      "| epoch  38 |     8/   12 batches | lr 0.000464 | 137.78 ms | loss 0.21526\n",
      "| epoch  38 |    10/   12 batches | lr 0.000464 | 135.37 ms | loss 0.15667\n",
      "| epoch  38 |    12/   12 batches | lr 0.000464 | 99.04 ms | loss 0.19286\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  39 |     2/   12 batches | lr 0.000455 | 198.40 ms | loss 0.30351\n",
      "| epoch  39 |     4/   12 batches | lr 0.000455 | 134.39 ms | loss 0.18845\n",
      "| epoch  39 |     6/   12 batches | lr 0.000455 | 136.86 ms | loss 0.14604\n",
      "| epoch  39 |     8/   12 batches | lr 0.000455 | 134.62 ms | loss 0.13653\n",
      "| epoch  39 |    10/   12 batches | lr 0.000455 | 140.24 ms | loss 0.16192\n",
      "| epoch  39 |    12/   12 batches | lr 0.000455 | 96.35 ms | loss 0.28874\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  40 |     2/   12 batches | lr 0.000446 | 198.20 ms | loss 0.27654\n",
      "| epoch  40 |     4/   12 batches | lr 0.000446 | 134.19 ms | loss 0.13986\n",
      "| epoch  40 |     6/   12 batches | lr 0.000446 | 134.49 ms | loss 0.15769\n",
      "| epoch  40 |     8/   12 batches | lr 0.000446 | 138.20 ms | loss 0.10544\n",
      "| epoch  40 |    10/   12 batches | lr 0.000446 | 134.46 ms | loss 0.15064\n",
      "| epoch  40 |    12/   12 batches | lr 0.000446 | 98.98 ms | loss 0.13037\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  41 |     2/   12 batches | lr 0.000437 | 199.34 ms | loss 0.21942\n",
      "| epoch  41 |     4/   12 batches | lr 0.000437 | 134.36 ms | loss 0.18847\n",
      "| epoch  41 |     6/   12 batches | lr 0.000437 | 136.82 ms | loss 0.10011\n",
      "| epoch  41 |     8/   12 batches | lr 0.000437 | 138.04 ms | loss 0.11991\n",
      "| epoch  41 |    10/   12 batches | lr 0.000437 | 134.58 ms | loss 0.11372\n",
      "| epoch  41 |    12/   12 batches | lr 0.000437 | 96.40 ms | loss 0.16636\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  42 |     2/   12 batches | lr 0.000428 | 201.37 ms | loss 0.23496\n",
      "| epoch  42 |     4/   12 batches | lr 0.000428 | 143.06 ms | loss 0.20733\n",
      "| epoch  42 |     6/   12 batches | lr 0.000428 | 134.35 ms | loss 0.22886\n",
      "| epoch  42 |     8/   12 batches | lr 0.000428 | 134.99 ms | loss 0.14445\n",
      "| epoch  42 |    10/   12 batches | lr 0.000428 | 137.39 ms | loss 0.19380\n",
      "| epoch  42 |    12/   12 batches | lr 0.000428 | 96.18 ms | loss 0.13777\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  43 |     2/   12 batches | lr 0.000419 | 201.99 ms | loss 0.33565\n",
      "| epoch  43 |     4/   12 batches | lr 0.000419 | 137.17 ms | loss 0.08998\n",
      "| epoch  43 |     6/   12 batches | lr 0.000419 | 134.54 ms | loss 0.27475\n",
      "| epoch  43 |     8/   12 batches | lr 0.000419 | 134.49 ms | loss 0.29319\n",
      "| epoch  43 |    10/   12 batches | lr 0.000419 | 139.59 ms | loss 0.10155\n",
      "| epoch  43 |    12/   12 batches | lr 0.000419 | 97.22 ms | loss 0.30119\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  44 |     2/   12 batches | lr 0.000411 | 197.93 ms | loss 0.19806\n",
      "| epoch  44 |     4/   12 batches | lr 0.000411 | 138.94 ms | loss 0.21966\n",
      "| epoch  44 |     6/   12 batches | lr 0.000411 | 134.55 ms | loss 0.16838\n",
      "| epoch  44 |     8/   12 batches | lr 0.000411 | 134.51 ms | loss 0.12011\n",
      "| epoch  44 |    10/   12 batches | lr 0.000411 | 136.83 ms | loss 0.16113\n",
      "| epoch  44 |    12/   12 batches | lr 0.000411 | 98.77 ms | loss 0.12526\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  45 |     2/   12 batches | lr 0.000403 | 198.72 ms | loss 0.19602\n",
      "| epoch  45 |     4/   12 batches | lr 0.000403 | 137.21 ms | loss 0.11594\n",
      "| epoch  45 |     6/   12 batches | lr 0.000403 | 138.68 ms | loss 0.11985\n",
      "| epoch  45 |     8/   12 batches | lr 0.000403 | 135.32 ms | loss 0.12788\n",
      "| epoch  45 |    10/   12 batches | lr 0.000403 | 135.04 ms | loss 0.06248\n",
      "| epoch  45 |    12/   12 batches | lr 0.000403 | 96.15 ms | loss 0.18026\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  46 |     2/   12 batches | lr 0.000395 | 198.09 ms | loss 0.14121\n",
      "| epoch  46 |     4/   12 batches | lr 0.000395 | 136.90 ms | loss 0.14202\n",
      "| epoch  46 |     6/   12 batches | lr 0.000395 | 146.96 ms | loss 0.19561\n",
      "| epoch  46 |     8/   12 batches | lr 0.000395 | 134.65 ms | loss 0.14948\n",
      "| epoch  46 |    10/   12 batches | lr 0.000395 | 134.40 ms | loss 0.14054\n",
      "| epoch  46 |    12/   12 batches | lr 0.000395 | 96.28 ms | loss 0.09801\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  47 |     2/   12 batches | lr 0.000387 | 203.73 ms | loss 0.15000\n",
      "| epoch  47 |     4/   12 batches | lr 0.000387 | 141.83 ms | loss 0.08802\n",
      "| epoch  47 |     6/   12 batches | lr 0.000387 | 134.36 ms | loss 0.10693\n",
      "| epoch  47 |     8/   12 batches | lr 0.000387 | 137.91 ms | loss 0.18664\n",
      "| epoch  47 |    10/   12 batches | lr 0.000387 | 134.78 ms | loss 0.07112\n",
      "| epoch  47 |    12/   12 batches | lr 0.000387 | 96.25 ms | loss 0.11109\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  48 |     2/   12 batches | lr 0.000379 | 201.34 ms | loss 0.28373\n",
      "| epoch  48 |     4/   12 batches | lr 0.000379 | 141.93 ms | loss 0.09798\n",
      "| epoch  48 |     6/   12 batches | lr 0.000379 | 134.38 ms | loss 0.10169\n",
      "| epoch  48 |     8/   12 batches | lr 0.000379 | 142.21 ms | loss 0.23068\n",
      "| epoch  48 |    10/   12 batches | lr 0.000379 | 143.76 ms | loss 0.13082\n",
      "| epoch  48 |    12/   12 batches | lr 0.000379 | 120.12 ms | loss 0.26650\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time:  1.90s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  49 |     2/   12 batches | lr 0.000372 | 373.98 ms | loss 0.22383\n",
      "| epoch  49 |     4/   12 batches | lr 0.000372 | 147.58 ms | loss 0.13616\n",
      "| epoch  49 |     6/   12 batches | lr 0.000372 | 142.56 ms | loss 0.11996\n",
      "| epoch  49 |     8/   12 batches | lr 0.000372 | 141.66 ms | loss 0.11477\n",
      "| epoch  49 |    10/   12 batches | lr 0.000372 | 184.63 ms | loss 0.16394\n",
      "| epoch  49 |    12/   12 batches | lr 0.000372 | 188.79 ms | loss 0.02638\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time:  2.49s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  50 |     2/   12 batches | lr 0.000364 | 249.02 ms | loss 0.16696\n",
      "| epoch  50 |     4/   12 batches | lr 0.000364 | 134.46 ms | loss 0.07682\n",
      "| epoch  50 |     6/   12 batches | lr 0.000364 | 139.66 ms | loss 0.11333\n",
      "| epoch  50 |     8/   12 batches | lr 0.000364 | 135.94 ms | loss 0.09415\n",
      "| epoch  50 |    10/   12 batches | lr 0.000364 | 138.31 ms | loss 0.07554\n",
      "| epoch  50 |    12/   12 batches | lr 0.000364 | 96.25 ms | loss 0.05442\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  1.94s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  51 |     2/   12 batches | lr 0.000357 | 256.75 ms | loss 0.25559\n",
      "| epoch  51 |     4/   12 batches | lr 0.000357 | 134.88 ms | loss 0.03903\n",
      "| epoch  51 |     6/   12 batches | lr 0.000357 | 137.09 ms | loss 0.08248\n",
      "| epoch  51 |     8/   12 batches | lr 0.000357 | 139.41 ms | loss 0.10142\n",
      "| epoch  51 |    10/   12 batches | lr 0.000357 | 134.99 ms | loss 0.05601\n",
      "| epoch  51 |    12/   12 batches | lr 0.000357 | 96.19 ms | loss 0.10504\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time:  1.95s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  52 |     2/   12 batches | lr 0.000350 | 198.35 ms | loss 0.10520\n",
      "| epoch  52 |     4/   12 batches | lr 0.000350 | 143.84 ms | loss 0.04286\n",
      "| epoch  52 |     6/   12 batches | lr 0.000350 | 136.91 ms | loss 0.10320\n",
      "| epoch  52 |     8/   12 batches | lr 0.000350 | 135.08 ms | loss 0.05404\n",
      "| epoch  52 |    10/   12 batches | lr 0.000350 | 137.32 ms | loss 0.12288\n",
      "| epoch  52 |    12/   12 batches | lr 0.000350 | 96.21 ms | loss 0.03098\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  53 |     2/   12 batches | lr 0.000343 | 204.59 ms | loss 0.12552\n",
      "| epoch  53 |     4/   12 batches | lr 0.000343 | 135.05 ms | loss 0.07701\n",
      "| epoch  53 |     6/   12 batches | lr 0.000343 | 134.35 ms | loss 0.02800\n",
      "| epoch  53 |     8/   12 batches | lr 0.000343 | 137.07 ms | loss 0.08035\n",
      "| epoch  53 |    10/   12 batches | lr 0.000343 | 134.74 ms | loss 0.13041\n",
      "| epoch  53 |    12/   12 batches | lr 0.000343 | 99.09 ms | loss 0.04965\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  54 |     2/   12 batches | lr 0.000336 | 201.53 ms | loss 0.12733\n",
      "| epoch  54 |     4/   12 batches | lr 0.000336 | 134.34 ms | loss 0.03559\n",
      "| epoch  54 |     6/   12 batches | lr 0.000336 | 134.54 ms | loss 0.06801\n",
      "| epoch  54 |     8/   12 batches | lr 0.000336 | 134.88 ms | loss 0.02731\n",
      "| epoch  54 |    10/   12 batches | lr 0.000336 | 137.89 ms | loss 0.09650\n",
      "| epoch  54 |    12/   12 batches | lr 0.000336 | 96.29 ms | loss 0.14870\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  55 |     2/   12 batches | lr 0.000329 | 198.31 ms | loss 0.08558\n",
      "| epoch  55 |     4/   12 batches | lr 0.000329 | 137.14 ms | loss 0.07897\n",
      "| epoch  55 |     6/   12 batches | lr 0.000329 | 134.61 ms | loss 0.04297\n",
      "| epoch  55 |     8/   12 batches | lr 0.000329 | 137.06 ms | loss 0.06977\n",
      "| epoch  55 |    10/   12 batches | lr 0.000329 | 137.02 ms | loss 0.05063\n",
      "| epoch  55 |    12/   12 batches | lr 0.000329 | 96.20 ms | loss 0.08287\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  56 |     2/   12 batches | lr 0.000323 | 202.44 ms | loss 0.09135\n",
      "| epoch  56 |     4/   12 batches | lr 0.000323 | 137.93 ms | loss 0.05487\n",
      "| epoch  56 |     6/   12 batches | lr 0.000323 | 137.18 ms | loss 0.06445\n",
      "| epoch  56 |     8/   12 batches | lr 0.000323 | 134.99 ms | loss 0.08956\n",
      "| epoch  56 |    10/   12 batches | lr 0.000323 | 137.26 ms | loss 0.05857\n",
      "| epoch  56 |    12/   12 batches | lr 0.000323 | 99.38 ms | loss 0.06066\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  57 |     2/   12 batches | lr 0.000316 | 200.71 ms | loss 0.09969\n",
      "| epoch  57 |     4/   12 batches | lr 0.000316 | 142.99 ms | loss 0.07622\n",
      "| epoch  57 |     6/   12 batches | lr 0.000316 | 137.73 ms | loss 0.03532\n",
      "| epoch  57 |     8/   12 batches | lr 0.000316 | 134.54 ms | loss 0.07098\n",
      "| epoch  57 |    10/   12 batches | lr 0.000316 | 134.36 ms | loss 0.07794\n",
      "| epoch  57 |    12/   12 batches | lr 0.000316 | 96.15 ms | loss 0.02955\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  58 |     2/   12 batches | lr 0.000310 | 199.73 ms | loss 0.05741\n",
      "| epoch  58 |     4/   12 batches | lr 0.000310 | 137.72 ms | loss 0.02949\n",
      "| epoch  58 |     6/   12 batches | lr 0.000310 | 135.35 ms | loss 0.05125\n",
      "| epoch  58 |     8/   12 batches | lr 0.000310 | 134.84 ms | loss 0.03423\n",
      "| epoch  58 |    10/   12 batches | lr 0.000310 | 134.34 ms | loss 0.07361\n",
      "| epoch  58 |    12/   12 batches | lr 0.000310 | 98.75 ms | loss 0.01823\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  59 |     2/   12 batches | lr 0.000304 | 200.50 ms | loss 0.07391\n",
      "| epoch  59 |     4/   12 batches | lr 0.000304 | 141.23 ms | loss 0.08254\n",
      "| epoch  59 |     6/   12 batches | lr 0.000304 | 138.65 ms | loss 0.05724\n",
      "| epoch  59 |     8/   12 batches | lr 0.000304 | 138.95 ms | loss 0.02364\n",
      "| epoch  59 |    10/   12 batches | lr 0.000304 | 135.06 ms | loss 0.02811\n",
      "| epoch  59 |    12/   12 batches | lr 0.000304 | 96.19 ms | loss 0.05090\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  60 |     2/   12 batches | lr 0.000298 | 200.53 ms | loss 0.05212\n",
      "| epoch  60 |     4/   12 batches | lr 0.000298 | 141.55 ms | loss 0.04429\n",
      "| epoch  60 |     6/   12 batches | lr 0.000298 | 137.96 ms | loss 0.05135\n",
      "| epoch  60 |     8/   12 batches | lr 0.000298 | 139.38 ms | loss 0.01689\n",
      "| epoch  60 |    10/   12 batches | lr 0.000298 | 135.10 ms | loss 0.02902\n",
      "| epoch  60 |    12/   12 batches | lr 0.000298 | 96.23 ms | loss 0.02750\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  61 |     2/   12 batches | lr 0.000292 | 201.14 ms | loss 0.05792\n",
      "| epoch  61 |     4/   12 batches | lr 0.000292 | 137.05 ms | loss 0.01912\n",
      "| epoch  61 |     6/   12 batches | lr 0.000292 | 134.33 ms | loss 0.02308\n",
      "| epoch  61 |     8/   12 batches | lr 0.000292 | 137.90 ms | loss 0.01963\n",
      "| epoch  61 |    10/   12 batches | lr 0.000292 | 136.12 ms | loss 0.02709\n",
      "| epoch  61 |    12/   12 batches | lr 0.000292 | 96.40 ms | loss 0.04822\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  62 |     2/   12 batches | lr 0.000286 | 203.14 ms | loss 0.11035\n",
      "| epoch  62 |     4/   12 batches | lr 0.000286 | 135.49 ms | loss 0.03559\n",
      "| epoch  62 |     6/   12 batches | lr 0.000286 | 134.87 ms | loss 0.01554\n",
      "| epoch  62 |     8/   12 batches | lr 0.000286 | 134.45 ms | loss 0.03044\n",
      "| epoch  62 |    10/   12 batches | lr 0.000286 | 142.18 ms | loss 0.05692\n",
      "| epoch  62 |    12/   12 batches | lr 0.000286 | 99.04 ms | loss 0.07123\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  63 |     2/   12 batches | lr 0.000280 | 198.13 ms | loss 0.06876\n",
      "| epoch  63 |     4/   12 batches | lr 0.000280 | 134.71 ms | loss 0.03399\n",
      "| epoch  63 |     6/   12 batches | lr 0.000280 | 137.62 ms | loss 0.04380\n",
      "| epoch  63 |     8/   12 batches | lr 0.000280 | 134.65 ms | loss 0.02288\n",
      "| epoch  63 |    10/   12 batches | lr 0.000280 | 137.84 ms | loss 0.01590\n",
      "| epoch  63 |    12/   12 batches | lr 0.000280 | 99.96 ms | loss 0.04433\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  64 |     2/   12 batches | lr 0.000274 | 198.00 ms | loss 0.06571\n",
      "| epoch  64 |     4/   12 batches | lr 0.000274 | 141.16 ms | loss 0.18245\n",
      "| epoch  64 |     6/   12 batches | lr 0.000274 | 136.94 ms | loss 0.06340\n",
      "| epoch  64 |     8/   12 batches | lr 0.000274 | 137.14 ms | loss 0.10822\n",
      "| epoch  64 |    10/   12 batches | lr 0.000274 | 134.20 ms | loss 0.18259\n",
      "| epoch  64 |    12/   12 batches | lr 0.000274 | 99.65 ms | loss 0.04228\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  65 |     2/   12 batches | lr 0.000269 | 199.26 ms | loss 0.33732\n",
      "| epoch  65 |     4/   12 batches | lr 0.000269 | 144.22 ms | loss 0.03181\n",
      "| epoch  65 |     6/   12 batches | lr 0.000269 | 134.70 ms | loss 0.05746\n",
      "| epoch  65 |     8/   12 batches | lr 0.000269 | 138.11 ms | loss 0.09898\n",
      "| epoch  65 |    10/   12 batches | lr 0.000269 | 134.46 ms | loss 0.20276\n",
      "| epoch  65 |    12/   12 batches | lr 0.000269 | 96.29 ms | loss 0.02235\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  66 |     2/   12 batches | lr 0.000264 | 205.16 ms | loss 0.24099\n",
      "| epoch  66 |     4/   12 batches | lr 0.000264 | 142.15 ms | loss 0.14714\n",
      "| epoch  66 |     6/   12 batches | lr 0.000264 | 134.45 ms | loss 0.05257\n",
      "| epoch  66 |     8/   12 batches | lr 0.000264 | 137.88 ms | loss 0.06951\n",
      "| epoch  66 |    10/   12 batches | lr 0.000264 | 134.37 ms | loss 0.10763\n",
      "| epoch  66 |    12/   12 batches | lr 0.000264 | 96.44 ms | loss 0.04910\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time:  1.86s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  67 |     2/   12 batches | lr 0.000258 | 201.05 ms | loss 0.08539\n",
      "| epoch  67 |     4/   12 batches | lr 0.000258 | 142.99 ms | loss 0.04779\n",
      "| epoch  67 |     6/   12 batches | lr 0.000258 | 134.36 ms | loss 0.07082\n",
      "| epoch  67 |     8/   12 batches | lr 0.000258 | 137.06 ms | loss 0.03396\n",
      "| epoch  67 |    10/   12 batches | lr 0.000258 | 137.21 ms | loss 0.04568\n",
      "| epoch  67 |    12/   12 batches | lr 0.000258 | 96.23 ms | loss 0.03920\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  68 |     2/   12 batches | lr 0.000253 | 198.09 ms | loss 0.05280\n",
      "| epoch  68 |     4/   12 batches | lr 0.000253 | 139.58 ms | loss 0.04623\n",
      "| epoch  68 |     6/   12 batches | lr 0.000253 | 135.04 ms | loss 0.01541\n",
      "| epoch  68 |     8/   12 batches | lr 0.000253 | 136.95 ms | loss 0.03358\n",
      "| epoch  68 |    10/   12 batches | lr 0.000253 | 136.84 ms | loss 0.03000\n",
      "| epoch  68 |    12/   12 batches | lr 0.000253 | 96.14 ms | loss 0.04937\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  69 |     2/   12 batches | lr 0.000248 | 198.52 ms | loss 0.10909\n",
      "| epoch  69 |     4/   12 batches | lr 0.000248 | 134.92 ms | loss 0.01448\n",
      "| epoch  69 |     6/   12 batches | lr 0.000248 | 143.81 ms | loss 0.02871\n",
      "| epoch  69 |     8/   12 batches | lr 0.000248 | 134.30 ms | loss 0.01470\n",
      "| epoch  69 |    10/   12 batches | lr 0.000248 | 134.32 ms | loss 0.02468\n",
      "| epoch  69 |    12/   12 batches | lr 0.000248 | 98.84 ms | loss 0.04107\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  70 |     2/   12 batches | lr 0.000243 | 198.12 ms | loss 0.02100\n",
      "| epoch  70 |     4/   12 batches | lr 0.000243 | 138.01 ms | loss 0.05368\n",
      "| epoch  70 |     6/   12 batches | lr 0.000243 | 138.64 ms | loss 0.02159\n",
      "| epoch  70 |     8/   12 batches | lr 0.000243 | 137.27 ms | loss 0.02296\n",
      "| epoch  70 |    10/   12 batches | lr 0.000243 | 134.85 ms | loss 0.02148\n",
      "| epoch  70 |    12/   12 batches | lr 0.000243 | 96.35 ms | loss 0.04914\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  71 |     2/   12 batches | lr 0.000238 | 199.07 ms | loss 0.01543\n",
      "| epoch  71 |     4/   12 batches | lr 0.000238 | 145.35 ms | loss 0.05168\n",
      "| epoch  71 |     6/   12 batches | lr 0.000238 | 140.27 ms | loss 0.04961\n",
      "| epoch  71 |     8/   12 batches | lr 0.000238 | 134.42 ms | loss 0.03845\n",
      "| epoch  71 |    10/   12 batches | lr 0.000238 | 138.52 ms | loss 0.02318\n",
      "| epoch  71 |    12/   12 batches | lr 0.000238 | 98.92 ms | loss 0.03341\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time:  1.87s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  72 |     2/   12 batches | lr 0.000233 | 201.40 ms | loss 0.01591\n",
      "| epoch  72 |     4/   12 batches | lr 0.000233 | 134.37 ms | loss 0.02777\n",
      "| epoch  72 |     6/   12 batches | lr 0.000233 | 134.41 ms | loss 0.04412\n",
      "| epoch  72 |     8/   12 batches | lr 0.000233 | 138.18 ms | loss 0.03249\n",
      "| epoch  72 |    10/   12 batches | lr 0.000233 | 136.94 ms | loss 0.03176\n",
      "| epoch  72 |    12/   12 batches | lr 0.000233 | 99.54 ms | loss 0.01760\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  73 |     2/   12 batches | lr 0.000229 | 200.85 ms | loss 0.02326\n",
      "| epoch  73 |     4/   12 batches | lr 0.000229 | 134.48 ms | loss 0.08293\n",
      "| epoch  73 |     6/   12 batches | lr 0.000229 | 136.75 ms | loss 0.03938\n",
      "| epoch  73 |     8/   12 batches | lr 0.000229 | 134.46 ms | loss 0.03927\n",
      "| epoch  73 |    10/   12 batches | lr 0.000229 | 136.75 ms | loss 0.01548\n",
      "| epoch  73 |    12/   12 batches | lr 0.000229 | 96.14 ms | loss 0.01980\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  74 |     2/   12 batches | lr 0.000224 | 200.39 ms | loss 0.02124\n",
      "| epoch  74 |     4/   12 batches | lr 0.000224 | 136.88 ms | loss 0.03672\n",
      "| epoch  74 |     6/   12 batches | lr 0.000224 | 134.42 ms | loss 0.01511\n",
      "| epoch  74 |     8/   12 batches | lr 0.000224 | 134.30 ms | loss 0.02965\n",
      "| epoch  74 |    10/   12 batches | lr 0.000224 | 137.03 ms | loss 0.01415\n",
      "| epoch  74 |    12/   12 batches | lr 0.000224 | 96.30 ms | loss 0.02011\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  75 |     2/   12 batches | lr 0.000220 | 202.11 ms | loss 0.05818\n",
      "| epoch  75 |     4/   12 batches | lr 0.000220 | 137.39 ms | loss 0.01803\n",
      "| epoch  75 |     6/   12 batches | lr 0.000220 | 134.93 ms | loss 0.01477\n",
      "| epoch  75 |     8/   12 batches | lr 0.000220 | 134.41 ms | loss 0.06043\n",
      "| epoch  75 |    10/   12 batches | lr 0.000220 | 137.94 ms | loss 0.01579\n",
      "| epoch  75 |    12/   12 batches | lr 0.000220 | 98.80 ms | loss 0.01219\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  76 |     2/   12 batches | lr 0.000215 | 201.37 ms | loss 0.01712\n",
      "| epoch  76 |     4/   12 batches | lr 0.000215 | 134.95 ms | loss 0.02813\n",
      "| epoch  76 |     6/   12 batches | lr 0.000215 | 136.89 ms | loss 0.01264\n",
      "| epoch  76 |     8/   12 batches | lr 0.000215 | 134.73 ms | loss 0.05654\n",
      "| epoch  76 |    10/   12 batches | lr 0.000215 | 136.91 ms | loss 0.01365\n",
      "| epoch  76 |    12/   12 batches | lr 0.000215 | 96.31 ms | loss 0.04277\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  77 |     2/   12 batches | lr 0.000211 | 198.41 ms | loss 0.01319\n",
      "| epoch  77 |     4/   12 batches | lr 0.000211 | 144.72 ms | loss 0.01835\n",
      "| epoch  77 |     6/   12 batches | lr 0.000211 | 138.13 ms | loss 0.02554\n",
      "| epoch  77 |     8/   12 batches | lr 0.000211 | 137.64 ms | loss 0.02010\n",
      "| epoch  77 |    10/   12 batches | lr 0.000211 | 134.38 ms | loss 0.02649\n",
      "| epoch  77 |    12/   12 batches | lr 0.000211 | 96.06 ms | loss 0.01175\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  78 |     2/   12 batches | lr 0.000207 | 201.14 ms | loss 0.02818\n",
      "| epoch  78 |     4/   12 batches | lr 0.000207 | 134.58 ms | loss 0.02743\n",
      "| epoch  78 |     6/   12 batches | lr 0.000207 | 139.46 ms | loss 0.01333\n",
      "| epoch  78 |     8/   12 batches | lr 0.000207 | 137.10 ms | loss 0.02471\n",
      "| epoch  78 |    10/   12 batches | lr 0.000207 | 134.97 ms | loss 0.02462\n",
      "| epoch  78 |    12/   12 batches | lr 0.000207 | 96.25 ms | loss 0.00698\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  79 |     2/   12 batches | lr 0.000203 | 203.23 ms | loss 0.01991\n",
      "| epoch  79 |     4/   12 batches | lr 0.000203 | 134.51 ms | loss 0.01761\n",
      "| epoch  79 |     6/   12 batches | lr 0.000203 | 134.61 ms | loss 0.01596\n",
      "| epoch  79 |     8/   12 batches | lr 0.000203 | 140.26 ms | loss 0.01803\n",
      "| epoch  79 |    10/   12 batches | lr 0.000203 | 134.69 ms | loss 0.01273\n",
      "| epoch  79 |    12/   12 batches | lr 0.000203 | 96.26 ms | loss 0.00801\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  80 |     2/   12 batches | lr 0.000199 | 203.74 ms | loss 0.06287\n",
      "| epoch  80 |     4/   12 batches | lr 0.000199 | 142.56 ms | loss 0.02376\n",
      "| epoch  80 |     6/   12 batches | lr 0.000199 | 134.57 ms | loss 0.00826\n",
      "| epoch  80 |     8/   12 batches | lr 0.000199 | 136.06 ms | loss 0.01247\n",
      "| epoch  80 |    10/   12 batches | lr 0.000199 | 140.64 ms | loss 0.01754\n",
      "| epoch  80 |    12/   12 batches | lr 0.000199 | 97.91 ms | loss 0.02861\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time:  1.86s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  81 |     2/   12 batches | lr 0.000195 | 201.05 ms | loss 0.02518\n",
      "| epoch  81 |     4/   12 batches | lr 0.000195 | 136.05 ms | loss 0.00909\n",
      "| epoch  81 |     6/   12 batches | lr 0.000195 | 134.39 ms | loss 0.03330\n",
      "| epoch  81 |     8/   12 batches | lr 0.000195 | 136.92 ms | loss 0.03790\n",
      "| epoch  81 |    10/   12 batches | lr 0.000195 | 137.67 ms | loss 0.01799\n",
      "| epoch  81 |    12/   12 batches | lr 0.000195 | 97.47 ms | loss 0.02508\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  82 |     2/   12 batches | lr 0.000191 | 198.54 ms | loss 0.07496\n",
      "| epoch  82 |     4/   12 batches | lr 0.000191 | 134.37 ms | loss 0.00705\n",
      "| epoch  82 |     6/   12 batches | lr 0.000191 | 138.70 ms | loss 0.01607\n",
      "| epoch  82 |     8/   12 batches | lr 0.000191 | 134.50 ms | loss 0.00658\n",
      "| epoch  82 |    10/   12 batches | lr 0.000191 | 134.30 ms | loss 0.03160\n",
      "| epoch  82 |    12/   12 batches | lr 0.000191 | 96.73 ms | loss 0.01016\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  83 |     2/   12 batches | lr 0.000187 | 198.58 ms | loss 0.02144\n",
      "| epoch  83 |     4/   12 batches | lr 0.000187 | 144.29 ms | loss 0.02421\n",
      "| epoch  83 |     6/   12 batches | lr 0.000187 | 138.15 ms | loss 0.02507\n",
      "| epoch  83 |     8/   12 batches | lr 0.000187 | 134.45 ms | loss 0.01906\n",
      "| epoch  83 |    10/   12 batches | lr 0.000187 | 134.41 ms | loss 0.04113\n",
      "| epoch  83 |    12/   12 batches | lr 0.000187 | 99.24 ms | loss 0.00661\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time:  1.86s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  84 |     2/   12 batches | lr 0.000183 | 201.42 ms | loss 0.01414\n",
      "| epoch  84 |     4/   12 batches | lr 0.000183 | 134.21 ms | loss 0.01650\n",
      "| epoch  84 |     6/   12 batches | lr 0.000183 | 134.80 ms | loss 0.01738\n",
      "| epoch  84 |     8/   12 batches | lr 0.000183 | 137.08 ms | loss 0.02534\n",
      "| epoch  84 |    10/   12 batches | lr 0.000183 | 135.00 ms | loss 0.01232\n",
      "| epoch  84 |    12/   12 batches | lr 0.000183 | 98.90 ms | loss 0.02095\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  85 |     2/   12 batches | lr 0.000180 | 204.28 ms | loss 0.02218\n",
      "| epoch  85 |     4/   12 batches | lr 0.000180 | 135.12 ms | loss 0.02875\n",
      "| epoch  85 |     6/   12 batches | lr 0.000180 | 135.01 ms | loss 0.03318\n",
      "| epoch  85 |     8/   12 batches | lr 0.000180 | 137.58 ms | loss 0.02029\n",
      "| epoch  85 |    10/   12 batches | lr 0.000180 | 137.52 ms | loss 0.00454\n",
      "| epoch  85 |    12/   12 batches | lr 0.000180 | 96.16 ms | loss 0.00404\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  86 |     2/   12 batches | lr 0.000176 | 200.98 ms | loss 0.03390\n",
      "| epoch  86 |     4/   12 batches | lr 0.000176 | 135.63 ms | loss 0.01747\n",
      "| epoch  86 |     6/   12 batches | lr 0.000176 | 135.06 ms | loss 0.01009\n",
      "| epoch  86 |     8/   12 batches | lr 0.000176 | 138.06 ms | loss 0.01861\n",
      "| epoch  86 |    10/   12 batches | lr 0.000176 | 137.05 ms | loss 0.00473\n",
      "| epoch  86 |    12/   12 batches | lr 0.000176 | 96.23 ms | loss 0.01561\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  87 |     2/   12 batches | lr 0.000172 | 198.06 ms | loss 0.01723\n",
      "| epoch  87 |     4/   12 batches | lr 0.000172 | 139.63 ms | loss 0.00951\n",
      "| epoch  87 |     6/   12 batches | lr 0.000172 | 135.93 ms | loss 0.01036\n",
      "| epoch  87 |     8/   12 batches | lr 0.000172 | 134.42 ms | loss 0.02295\n",
      "| epoch  87 |    10/   12 batches | lr 0.000172 | 136.17 ms | loss 0.01953\n",
      "| epoch  87 |    12/   12 batches | lr 0.000172 | 96.84 ms | loss 0.01484\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  88 |     2/   12 batches | lr 0.000169 | 201.03 ms | loss 0.02967\n",
      "| epoch  88 |     4/   12 batches | lr 0.000169 | 137.40 ms | loss 0.00892\n",
      "| epoch  88 |     6/   12 batches | lr 0.000169 | 134.48 ms | loss 0.01031\n",
      "| epoch  88 |     8/   12 batches | lr 0.000169 | 137.32 ms | loss 0.03433\n",
      "| epoch  88 |    10/   12 batches | lr 0.000169 | 134.52 ms | loss 0.00834\n",
      "| epoch  88 |    12/   12 batches | lr 0.000169 | 98.95 ms | loss 0.00677\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  89 |     2/   12 batches | lr 0.000166 | 197.89 ms | loss 0.00983\n",
      "| epoch  89 |     4/   12 batches | lr 0.000166 | 136.14 ms | loss 0.01364\n",
      "| epoch  89 |     6/   12 batches | lr 0.000166 | 137.02 ms | loss 0.01394\n",
      "| epoch  89 |     8/   12 batches | lr 0.000166 | 134.82 ms | loss 0.04773\n",
      "| epoch  89 |    10/   12 batches | lr 0.000166 | 139.76 ms | loss 0.01464\n",
      "| epoch  89 |    12/   12 batches | lr 0.000166 | 96.45 ms | loss 0.00434\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  90 |     2/   12 batches | lr 0.000162 | 198.73 ms | loss 0.01131\n",
      "| epoch  90 |     4/   12 batches | lr 0.000162 | 134.21 ms | loss 0.01174\n",
      "| epoch  90 |     6/   12 batches | lr 0.000162 | 134.73 ms | loss 0.01006\n",
      "| epoch  90 |     8/   12 batches | lr 0.000162 | 138.38 ms | loss 0.01709\n",
      "| epoch  90 |    10/   12 batches | lr 0.000162 | 136.38 ms | loss 0.01378\n",
      "| epoch  90 |    12/   12 batches | lr 0.000162 | 96.41 ms | loss 0.01903\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  91 |     2/   12 batches | lr 0.000159 | 200.65 ms | loss 0.02305\n",
      "| epoch  91 |     4/   12 batches | lr 0.000159 | 134.35 ms | loss 0.00429\n",
      "| epoch  91 |     6/   12 batches | lr 0.000159 | 138.71 ms | loss 0.00395\n",
      "| epoch  91 |     8/   12 batches | lr 0.000159 | 138.11 ms | loss 0.02755\n",
      "| epoch  91 |    10/   12 batches | lr 0.000159 | 135.07 ms | loss 0.01223\n",
      "| epoch  91 |    12/   12 batches | lr 0.000159 | 99.68 ms | loss 0.00470\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  92 |     2/   12 batches | lr 0.000156 | 204.02 ms | loss 0.01644\n",
      "| epoch  92 |     4/   12 batches | lr 0.000156 | 135.59 ms | loss 0.00622\n",
      "| epoch  92 |     6/   12 batches | lr 0.000156 | 134.93 ms | loss 0.01154\n",
      "| epoch  92 |     8/   12 batches | lr 0.000156 | 134.38 ms | loss 0.01052\n",
      "| epoch  92 |    10/   12 batches | lr 0.000156 | 137.65 ms | loss 0.02338\n",
      "| epoch  92 |    12/   12 batches | lr 0.000156 | 96.25 ms | loss 0.04735\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  93 |     2/   12 batches | lr 0.000153 | 204.62 ms | loss 0.03536\n",
      "| epoch  93 |     4/   12 batches | lr 0.000153 | 137.04 ms | loss 0.00519\n",
      "| epoch  93 |     6/   12 batches | lr 0.000153 | 134.42 ms | loss 0.00402\n",
      "| epoch  93 |     8/   12 batches | lr 0.000153 | 134.60 ms | loss 0.00434\n",
      "| epoch  93 |    10/   12 batches | lr 0.000153 | 137.45 ms | loss 0.01773\n",
      "| epoch  93 |    12/   12 batches | lr 0.000153 | 97.32 ms | loss 0.01481\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  94 |     2/   12 batches | lr 0.000150 | 201.19 ms | loss 0.03345\n",
      "| epoch  94 |     4/   12 batches | lr 0.000150 | 135.56 ms | loss 0.01050\n",
      "| epoch  94 |     6/   12 batches | lr 0.000150 | 134.37 ms | loss 0.01080\n",
      "| epoch  94 |     8/   12 batches | lr 0.000150 | 134.97 ms | loss 0.00399\n",
      "| epoch  94 |    10/   12 batches | lr 0.000150 | 138.11 ms | loss 0.01116\n",
      "| epoch  94 |    12/   12 batches | lr 0.000150 | 98.76 ms | loss 0.00890\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  95 |     2/   12 batches | lr 0.000147 | 198.09 ms | loss 0.02093\n",
      "| epoch  95 |     4/   12 batches | lr 0.000147 | 143.62 ms | loss 0.01250\n",
      "| epoch  95 |     6/   12 batches | lr 0.000147 | 139.59 ms | loss 0.02350\n",
      "| epoch  95 |     8/   12 batches | lr 0.000147 | 134.64 ms | loss 0.00451\n",
      "| epoch  95 |    10/   12 batches | lr 0.000147 | 134.29 ms | loss 0.01866\n",
      "| epoch  95 |    12/   12 batches | lr 0.000147 | 96.40 ms | loss 0.02626\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time:  1.85s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  96 |     2/   12 batches | lr 0.000144 | 201.27 ms | loss 0.02456\n",
      "| epoch  96 |     4/   12 batches | lr 0.000144 | 137.08 ms | loss 0.01006\n",
      "| epoch  96 |     6/   12 batches | lr 0.000144 | 140.44 ms | loss 0.00753\n",
      "| epoch  96 |     8/   12 batches | lr 0.000144 | 134.95 ms | loss 0.00248\n",
      "| epoch  96 |    10/   12 batches | lr 0.000144 | 134.51 ms | loss 0.02076\n",
      "| epoch  96 |    12/   12 batches | lr 0.000144 | 96.38 ms | loss 0.01787\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  97 |     2/   12 batches | lr 0.000141 | 202.72 ms | loss 0.01517\n",
      "| epoch  97 |     4/   12 batches | lr 0.000141 | 141.44 ms | loss 0.00652\n",
      "| epoch  97 |     6/   12 batches | lr 0.000141 | 139.74 ms | loss 0.00997\n",
      "| epoch  97 |     8/   12 batches | lr 0.000141 | 135.75 ms | loss 0.01388\n",
      "| epoch  97 |    10/   12 batches | lr 0.000141 | 135.10 ms | loss 0.00151\n",
      "| epoch  97 |    12/   12 batches | lr 0.000141 | 96.23 ms | loss 0.00433\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time:  1.86s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  98 |     2/   12 batches | lr 0.000138 | 201.16 ms | loss 0.00685\n",
      "| epoch  98 |     4/   12 batches | lr 0.000138 | 134.83 ms | loss 0.00584\n",
      "| epoch  98 |     6/   12 batches | lr 0.000138 | 134.48 ms | loss 0.00415\n",
      "| epoch  98 |     8/   12 batches | lr 0.000138 | 137.53 ms | loss 0.00463\n",
      "| epoch  98 |    10/   12 batches | lr 0.000138 | 137.98 ms | loss 0.00350\n",
      "| epoch  98 |    12/   12 batches | lr 0.000138 | 96.21 ms | loss 0.00951\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time:  1.83s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  99 |     2/   12 batches | lr 0.000135 | 197.96 ms | loss 0.00734\n",
      "| epoch  99 |     4/   12 batches | lr 0.000135 | 137.24 ms | loss 0.01308\n",
      "| epoch  99 |     6/   12 batches | lr 0.000135 | 134.52 ms | loss 0.00553\n",
      "| epoch  99 |     8/   12 batches | lr 0.000135 | 137.06 ms | loss 0.01336\n",
      "| epoch  99 |    10/   12 batches | lr 0.000135 | 141.11 ms | loss 0.00671\n",
      "| epoch  99 |    12/   12 batches | lr 0.000135 | 96.26 ms | loss 0.01275\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/home-hd/Anaconda/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 100 |     2/   12 batches | lr 0.000133 | 201.05 ms | loss 0.01198\n",
      "| epoch 100 |     4/   12 batches | lr 0.000133 | 135.22 ms | loss 0.02621\n",
      "| epoch 100 |     6/   12 batches | lr 0.000133 | 137.15 ms | loss 0.00638\n",
      "| epoch 100 |     8/   12 batches | lr 0.000133 | 134.89 ms | loss 0.01928\n",
      "| epoch 100 |    10/   12 batches | lr 0.000133 | 134.90 ms | loss 0.00580\n",
      "| epoch 100 |    12/   12 batches | lr 0.000133 | 100.74 ms | loss 0.00784\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  1.84s |\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "seed_torch()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-03)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
    "loss, val_loss, acc, val_acc =  train(model, 100, batch_size, train_loader, criterion,\n",
    "      optimizer, scheduler, set_size, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee9f5e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Erro')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(loss, label='treino', linestyle='dashed', marker='^')\n",
    "plt.plot(val_loss, label='validação', linestyle='dashed', marker='v')\n",
    "plt.legend()\n",
    "plt.title(\"Erro por epoca de treinamento\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Erro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0973b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Acurácia (%)')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEYCAYAAABRB/GsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABOFklEQVR4nO2deXhVxfn4P28WCEIEZIewKQgiu4i2iqBYN9zrhru1tbUqahe0fq1Va3+1q5VqXdoq1YoouNSqdaNa3ElYRHaQfQlhTQAJJDfv7485J/fcm3tvbkJuQnLfz/PcJ/fMmTPzzpybeWfeeWdGVBXDMAwjfcloaAEMwzCMhsUUgWEYRppjisAwDCPNMUVgGIaR5pgiMAzDSHNMERiGYaQ5pgiMpBCRbBGZJyLjkoz/HxG5JtVyNRVEZIyIrG/A/O19pTFZDS2AUXtE5ANgCNBZVfelOLufAa+r6hvJRFbVM1Msj+EhIpOB9ap6d23TaIzvS0TuBfqo6pUNLUtjx0YEjRQR6QWMAhQ4NwXpi4hkeN8zgZ3APXWdj5F6RMQ6fEZiVNU+jfCDa5Q/Bv6I66kH73UHXga2ANuAR7zwe4F/BuL1wimSLO/6A+BXXrp7gT7AdcBiYBewEvh+VF7nAfOAEuAr4IxAWt/1vh8B/NeTZSvwHNAmTrkeA34fFfYv4Efe9zuADZ48S4GxcdJpDvweWAtsBh4HWnj3xgDrgbs8eVYDVwSebQ0849XfGuBuICNw/3uBOlkEDPfC7/TqwA+/IMH7awFMBnZ4cX+K69X797sCL3kyrAImxEnnBqAM2A/sBv7tha/26mo+sA83+j8e+ASn1L8AxgTSCb6va4GPvPrb4eV/ZiBu3N9EoG4nAkXAJuB84CxgGbAduCsQPyNQb9uAF4HDon6f13jvcSvwf969M7wyl3nl/iJQb695+awAvtfQ/6uN4dPgAtinli/O/ch/CBzj/TN08sIzvX/yh4CWQA5wonfvXqpXBGuBo72GIxs4B9eQCzAa+JpwwzcSKAa+5f1DdwP6B9LyG5Y+XpzmQAdgJvCnOOU6CVgHiHfdFqeUugL9vHtdA/IfESedh7wG4TAgF/g38Gvv3higHKdEm3vl2gP08+4/g1M+uV4ey4DrvXsX4xTRsV6d9AF6Bu519eriUi/NLnHkexD40JOvO7AATxF4z8/GKftmwOG4Bvf0OGlNBh6ICluNU9DdcUqnG66hPctL/1vedYcY7+ta3G/qe7jf043AxsA7GZfgN+HX7T2438/3cMpsilefR3vvs7cX/1bgMyDPexdPAM9H/T7/6pVhCE6pHRXr9+yFzQT+gvvdD/XyPqWh/18P9k+DC2CfWrw0ONH7R23vXS8Bbve+f8P78WfFeC7iH4fYiuD+avJ+FbjV+/4E8FCceJUNS4x75wNz49wTnDI6ybv+HvBf73sfXC/zVCA7gYyCa4SPCIR9A1jlffcbq5aB+y8CP/cavv3AgMC97wMfeN/f9sufxHuaB5wX595KvNGTd30DYUVwHLA2Kv7PgKfjpDWZ2IrgO4HrO4Bno+K8DVwT/b5wimBFIN4h3u+kcxK/iTG4hj7Tu871nj0uEH82cL73fTGBUR3QBffbzgr8PvMC92cBl8X5PXcHQkBuIOzXwOQD+X9Lh4/NETROrgHeUdWt3vUULwzcP8MaVS2vZdrrghciMlZEPhCRtSKyGtcItw/k9VV1CYpIJxGZKiIbRKQE+GcgjQjU/fdOBcZ7QZfjTEmo6grgNlwDUOSl2TVGMh1wjddsEdkpIjuBt7xwnx2quidwvQbXm2+P68muibrXrboyi8jVnmeVn+fAeOX08grWdTC/nkBXPx0vrbuATnHSikcw/Z7AxVFpnohreGNR6H9R1a+9r60ARORMEflMRLZ76ZxFZDm3qWrI+77X+7s5cH+vn5Yn1ysBmRbjGvNgWQsD378OPBtNV2C7qu4KhAXfnREHUwSNDBFpAVwCjBaRQhEpBG4HhojIENw/f484E4R7cA2kT+cYcTSQVzOcieQPOPNHL2AGrseNl9cRSYj9/7x0B6nqocCVgTRi8TxwkYj0xPWOX6oUTnWKqp6Ia0AU+E2M57fiGpujVbWN92mtqsEGpK2ItAxc98CZP7bieqQ9o+5t8L7HLLMn61+Bm4F2qtoGZ+6JV85NOKUSzMNnHW700ibwyVXVs+KkpUmEr8ONCIJptlTVB+M8GxMRaY57H7/HmSPbAG+S+H0mYh1u/iEoV46qbqj2yarl3ggcJiK5gbDguzPiYIqg8XE+rsc0AGcDHQochbM3X40bOm8CHhSRliKSIyIneM/OA04SkR4i0hpnbkhEc5xtdg+4niDOtuzzd+A6b9SQISLdRKR/jHRycRN6xSLSDTcxGhdVnYtrkP8GvK2qO738+4nIKV5jVIpr7CtiPF+Ba5QfEpGO3rPdROT0qKj3iUgzERkFnA1M83qyLwK/EpFcr4H/EW4UgyfTT0TkGM+zqo8XpyWuYdri5XcdbkQQjxeBn4lIWxHJA24J3JsF7BKRO0SkhYhkishAETk2TlqbcfMIifgncI6InO6ll+OtXcir5rlomuF+F1uAcu83cVoN0wjyOK6uewKISAcROS/JZzcDvXzvNlVdh5sM/7VXvsHA9YTfnREHUwSNj2twtuK1qlrof4BHgCtwPbNzcPb0tTgPjksBVPVd4AWcJ8ls4PVEGXlD7Am4HvoOnJnmtcD9WTgPkodwk8b/I7In7XMfMNyL8wbOo6k6puDMUFMCYc1xk6xbceaCjsRXZnfgJtQ/88xR7+Emm30KvTJtxJmefqCqS7x7t+CU30qc98wU4CmvzNNwnlVTcF4zr+K8XBbhRk6f4hqoQTjvq3jchzNbrALeAZ71b3jK6Gyckl9FWCm2jpPW34EBnnnl1VgRvEbyPJyJaQuuJ/5TatgGBH4TLxLjN1ELHvaef0dEduEmjo9L8tlp3t9tIjLH+z4eN7ewEXgF+IWqvncA8qUFvheAYaQNIjIGN8lY096wYTRJbERgGIaR5pgiMAzDSHPMNGQYhpHm2IjAMAwjzWl0m1G1b99ee/Xq1dBiGIZhNCpmz569VVU7xLrX6BRBr169KCgoaGgxDMMwGhUisibePTMNGYZhpDmmCAzDMNIcUwSGYRhpTqObI4hFWVkZ69evp7S0tKFFafTk5OSQl5dHdnZ2Q4tiGEY90SQUwfr168nNzaVXr16I1HYTRENV2bZtG+vXr6d3794NLY5hGPVEykxDIvKUiBSJyII490VEJonIChGZLyLDa5tXaWkp7dq1MyVwgIgI7dq1s5GV0aQoKinlkic+pWhX4t91svHqWqbofBPdSxWpnCOYjDtXNB5nAn29zw24s2prjSmBusHqsfHSUA1ZXT4TL86BlG3SjOXkr97OpBkrEuYXjBevMT6Q7/FkipYv3r1Uvt+UKQJVnYk7QDoe5wHPqOMzoI2IxDstyTDSmmQayEQNXl3LkGzjWtOGNl6c2jbSizYWM232elRhWsG6uPnd9fKXTM1fhypML1jHb95aUpnfw16ch99bXhn/T+8u56H3lsVssOPFCcr0YoGTacrna3g+kO+ijcWVcgTvvZgfKVNdk9K9hkSkF/C6qlY5oENEXgceVNWPvOsZwB2qWmW1mIjcgBs10KNHj2PWrIlcF7F48WKOOuqoui9AkuzcuZMpU6bwwx/+MOlnNm7cyIQJE5g+fXoKJasdDV2fRlXufuVLnpu1liuO68kD54f/ne58aT4v5K/jm0ccRsGanewrryAnK4OZd5xMx9wcwDXMNz8/l0cuH1YZlizBZye9t5znZq1l1BHt+WTlNsorlOZZGXwYyCtaVlR5btZa+nZsxbLNuwHIzhTOHdKVl+du4IrjelIequCF/HX0PKwFq7e7ky2bZWVwzuAuvDx3AyN6tKVgzQ4UyBQYdWQH/rdsC5eP7EFZqIJps9dzyTF5KDBt9vqIfDu0bE7R7n2Vso0+sj3d2x7Cc7PWMrpvez5csY1QhWsDBe8A7wwIVVQ9/ixDIDszg33lVc5CIkOgQqF5plABlIW0yv0x/Try/tIiWudks3NvWZU0sjOFXu1asqJod8wj5zJFCKlWeb/JIiKzVXVEzHuNQREEGTFihEavLK5Nw3Ug/xzRrF69mrPPPpsFCyKnQ8rLy8nKanzz8aYIUksyv71gnMLiUi74yyeEKiIbgTfmb+SmKXMrn8nOFMpCSnamcOmxPSoVRjwlkgz+s6cN6MQ7CzdXaaAyM+C8od1Yv2Mvj1w+jFVb9nD53z4nVKE0yxREpLLh9Bva4PfsDKGsIpxqsDFWhVCM5knE3Yt+1icrAzIzYjfYie5Vh3h5x8gyqTgZ1TybLNHvN1kSKYKGXEewgcgzW/Oox7NF63IYfeedd/LVV18xdOhQjj32WEaNGsW5557LgAEDCIVC/PSnP+XYY49l8ODBPPHEE4BTHgMHuhc5efJkLrzwQs444wz69u3LxIkTK9N+/vnnGTRoEAMHDuSOO+44YFmNhifeby+WyeKH/5zDhX/5uLLXWl6hPPifJZz2x/9xc0AJQLgXWhZSpuWv5YK/fBxhGpnumUaqw5fjvUWFvFDgTBPvLtocM26oAv41dwP5q7bz7b98wqVPflYpa1lIKQuFG9xgG+h/L49qGcPhsZUAOCXgPxuc0fK/hyqIyDda3nj3qkOpviFPFKculAC4ek32XSZLQ3ZXXwNuFpGpuKPpilV1U10kfOkTn1YJO3twF676Ri/27g9x+V8/Y976najCc5+vYeGGYi4/rgcXj+jO9j37ufGfsyOefeH730iY34MPPsiCBQuYN28eH3zwAePGjWPBggX07t2bJ598ktatW5Ofn8++ffs44YQTOO2006pMys6bN4+5c+fSvHlz+vXrxy233EJmZiZ33HEHs2fPpm3btpx22mm8+uqrnH/++QdcR0bqCfbqUbj5+bncdmpfpsxaW2n3nTC2T+WowG/8H3xzCW98uQlVKFizg+BPpbxCeXXuhmoblX0hZe7anXxncj4V6jfMFUyasaLanuRD7y1j1qrtzFoVnuJLlJ/fYK/bsZfMDKlUBEq40Y7HgbSN0c9q4G+8fJORqTEQUk3qXSZLyhSBiDwPjAHai8h64BdANoCqPg68CZyFO1f2a9zZt/XChp17I341G3burdP0R44cWemH/8477zB//vzKuYDi4mKWL1/OkUceGfHM2LFjad3aHUk7YMAA1qxZw7Zt2xgzZgwdOrgNA6+44gpmzpxpiuAgI56p54/vLiN/ldfzVyV/1Xau+vvnlY1qeUUFD/5nCet37OXecwZU9r5fnruB7EzX+guRJhWoWc+ysCRsHw8pvJC/loUbi3niqmNimqWKSkp5MX9dDUofRnBrUQ42fFMKqrxQsK6K/T5I86zamY1qK1MyDflZD3/Iok0lEWFlIWXOmh11Jk/KFIGqjq/mvgI3pSLvRD34XaVlFO8ti+g9lOwtY3Q/19ge1rJZtSOA6mjZsmXld1Xlz3/+M6effnpEnNWrV0dcN2/evPJ7ZmYm5eXlBySDUX8ETT0TTunDzc/P5arjejDVa1Cn5a9FRVCcacKnQp1ZpULh0ic+i2ig/O817cEO6HIoQ7q3ZuqsdTF722XeSCFeb/IXry2Ma5KJpm/HVqzd/nVlw5mMrMk0tPHi1LaRDjaasZTAgC6H8uato2qcbrIcaEOeStl8Gt9M5gEyacbyyqGyz4EOs3Jzc9m1a1fMe6effjqPPfYYp5xyCtnZ2Sxbtoxu3bolle7IkSOZMGECW7dupW3btjz//PPccssttZLRSEy8Xn11E7tFJaURNvi9+8vJjzKr7A8pIrFbSL9d2rUvvuL3e48TTunDqN++H9EYxvIQGvXb96s1uUwviDRL+c/GmwvwCTaad7/yJau37Ykpa12ZLJoC9dGQHyhppwjmrN1ZpVdwoMOsdu3accIJJzBw4EBatGhBp06dKu9997vfZfXq1QwfPhxVpUOHDrz66qtJpdulSxcefPBBTj75ZFSVcePGcd5559VaTiM+wV59sBGLF+4rCCE8+VheUcFLc6r6OxyoXdr/fSbTiYkVJ2gamTJrLRXqnvPNUv4cxtl//ojo9YSJGvZU/C8ZDUOjO7O4rtxHjfikW31uLt7LqN9+wP5QpA++37uO5Zt/18vzmTKrdrb07EzhnCFdeWP+poSmjmiTRSwTQ3S8eHGizTjgfPIroNKXf2qcuYFUm06M+iGR+2jajQiMpk9N14jc9sI89nu9er+Hff+5R3NZwBUy2PPetHNv3EYzGcpCyvtLiuL23OOZVZJpjOPFiWXG8TvzUz5bU2lKapaVwUe1WKxkNG5MERhNjnjmnFgs2VTCpyvD9nzfB/+dhYUU7doXEe7b1W98bnZSnjuJGvb68AQJEsuM4xMck2gduyUajQNTBEajJZaf/j1nD6jcn2VajAnR6Gc3xXAd3hfSCCXgU15RwZl/+pCS0sjtAXKyMujR7pDKLRR8EjXs9W1qCeYXNHlFE1R4NipIH0wRGAcNNfXciVihq0r+6u1MeH5uYGVr/AVUk2YsJ3/V9hotaCqvgG179pMRNaEaUmVk73a8c/voGpW3oYg1oRykrhcrGQc/dlSlcdAQb+uFWOFFJaWVOzg+H9ilceXWsB28wlu9G2vHzmmz13ubmAkf3XEyqx8cx+oHxzF+ZHe8tVxkZwpXHt+T1Q+O49pv9oxIN0hj85RJZCaCxlce48CxEYHRoPi9/bvHHRXhj++bJqL99P3wP7yzLDDBS1z/zP2hCs6e9BGvTzixcjTx0HvLKnvEGRnw+P9W8sD5AykqKeXlORsqJ1GDZpK9+8NmlMbuK28eQEY0NiJoAFq1agW4ragvuuiimHHGjBlDtJtsslx99dWMHj2aK6+8kr1763b7jLrGN9F8+7FPKhvnfeUV/L83FnPBox9z05Q5VfbKKSopZfqc9UnnUbRrX+Vz5z/yES/kh7cZCG7gFc9P/8H/LOHVeeH1AanY9MswGpL0GxE8fiIUflk1vPMg+MFH9SpK165dU3IewTPPPFPnaaaCwp17eX7WWpTIpf8KvDpvY5X4/l45/1mwCalyN0yslbjPz1rL/HU7mb+hOEa6ziYeb4FULFdPs6MbTYn0UwR5I2HLUgjtD4dlNnPhteTOO++ke/fu3HST2zrp3nvvJSsri/fff58dO3ZQVlbGAw88UGVVcPAcg71793LdddfxxRdf0L9//4ie/I033kh+fj579+7loosu4r777gMgPz+fW2+9lT179pCTk8PMmTP54osvuPXWWyktLaVFixY8/fTT9OvXj9LSUm688UYKCgrIysrij3/8IyeffHKty1wXfP+fs5Pe18anLKRs272/2jjRK3FDFRpTCQTjxzOZ1Lerp2HUN01TETw9rmrY0efDyO/BN2+B2U9H3qsoh3Z93Pc92+DFqyPvX/dGwuwuvfRSbrvttkpF8OKLL/L2228zYcIEDj30ULZu3crxxx/PueeeG/dM4Mcee4xDDjmExYsXM3/+fIYPH15571e/+hWHHXYYoVCIsWPHMn/+fPr3789ll13GtGnTGD58OMXFxWRnZ9O/f38+/PBDsrKyeO+997jrrrt46aWXePTRRxERvvzyS5YsWcJpp53GsmXLyMmpfxfBopJSxj/5GV9t3VN95DjEOhkrOo9Rv30/5qRoTW38ZlM3mjrpN0fQqhO07Ej4GAtx1zmta53ksGHDKCoqYuPGjXzxxRe0bduWzp07c9dddzF48GBOPfVUNmzYwObN8Tf0mjlzJldeeSUAgwcPZvDgwZX3XnzxRYYPH86wYcNYuHAhixYtYunSpXTp0qVSYbRu3ZqMjAyKi4u5+OKLGThwILfffjsLFy4E4KOPPqpMv3///vTs2ZNly5bVuswHwqQZy2MqgexM4cLh3WieFfmzzMnKYNb/jeXK43pUevRUeKaZRHnEc5E0G79hRNI0RwSJevDNDoHv/w8eHgLlpZDVHL4/E3K9jeJatqt2BBCLiy++mOnTp1NYWMill17Kc889x5YtW5g9ezbZ2dn06tWL0tKaNzyrVq3i97//Pfn5+bRt25Zrr702YTo///nPOfnkk3nllVdYvXo1Y8aMqXGeqcD3Dvruib2ZNjv2RG8ie/yD/1nCG/M3xfToiTUqqM5F0mz8hhEmpSMCETlDRJaKyAoRuTPG/Z4iMkNE5ovIByKSl0p5KsntDEOvAMlwf3M7Vf9MNVx66aVMnTqV6dOnc/HFF1NcXEzHjh3Jzs7m/fffZ82aNQmfP+mkk5gyZQoACxYsYP78+QCUlJTQsmVLWrduzebNm/nPf/4DQL9+/di0aRNz5swB3IE3FRUVFBcXV25zPXny5Mr0R40axXPPPQfAsmXLWLt2Lf369TvgcieLf+rVDc/OrtytM+in73+6tG5R4wnbWLx566jKNAd0ObTKfbPxG0aYVJ5Qlgk8CnwLWA/ki8hrqrooEO33wDOq+g8ROQX4NXBVqmSKYPRE2LIYRtfNOcBHH300u3btolu3bnTp0oUrrriCc845h0GDBjFixAj69++f8Pkbb7yR6667jqOOOoqjjjqKY445BoAhQ4YwbNgw+vfvT/fu3TnhhBMAaNasGVOnTuXGG29k3bp19OzZkw8++ICJEydyzTXX8MADDzBuXHiu5Ic//CE33ngjgwYNIisri8mTJ0cchpNKVhTtZmpgp86KBL36VEzYmo3fMBKTsm2oReQbwL2qerp3/TMAVf11IM5C4AxVXSduFrVYVat23wLYNtRV+c1vfsOFF15I37596yS92tZnvK0gLvzLx8xZuzPmM419cZZhNBYSbUOdStNQNyC4V+96LyzIF8CF3vcLgFwRaRedkIjcICIFIlKwZcuWlAjbWPnxj3/Mk08+SVlZWfWRU0y8rSDmrdsZ9xkz0RhGw9PQXkM/AUaLyFxgNLABCEVHUtUnVXWEqo7wD3I3HH/4wx/46quvGDBgQIPKEb0VhO+RM2nGcjKjdmmLnhsw041hNCypVAQbgO6B6zwvrBJV3aiqF6rqMOD/vLCdtcmssZ20drBS23qcNGN55SRwcBJ39toddpyhYRzkpNJ9NB/oKyK9cQrgMuDyYAQRaQ9sV9UK4GfAU7XJKCcnh23bttGuXbu4C7aM6lFVtm3bVuNFZkUlpbw4e32VSeCT+rZn2ebdPDJ+GGcP6ZoCiQ3DqAtSpghUtVxEbgbeBjKBp1R1oYjcDxSo6mvAGODXIqLATOCm2uSVl5fH+vXrsfmDAycnJ4e8vJp58U6asZyyqENO9pVXcPsL8whVKB8sKzJFYBgHMU3i8Hqj4Uh02pVP9MHvhmHUPw3lNWSkAZNmLGdfeQUtm2Wy5JdnVE4An350eJFeooVfhmE0PKYIjBpTVFLKJU98yqKNxZXbRZRXaOVZvkUlpXywNGyms719DOPgxhSBUWOCh8mEPNNicBO4eAe82KjAMA5OTBEYNaLyrGBgb1kF5TFO+op3wIu5jBrGwUnT3H3USBkPz1heeVZwNH6v3xaIGUbjwkYERtIUlZTyQv66uPet128YjRMbERhJUVRSytl//ohQRaTJxzaNM4zGjykCIykmzVhO0a59VcJtFGAYjR9TBEa1+FtIgC0OM4ymiM0RGNUS3ELC3EANo+lhisBISFFJKVPz1+HPDNjiMMNoepgiMOJSVFLKWZM+pLzCFocZRlPGFIERl0kzlrN19/4q4TZBbBhNC5ssNiLwzx2+95wBlfsIZWUIn/zsFJsgNowmio0IjAj8c4dveGZ25X5BIpgpyDCaMClVBCJyhogsFZEVInJnjPs9ROR9EZkrIvNF5KxUymPEJrib6NT8dajC+p17K/cLsgliw2japEwRiEgm8ChwJjAAGC8i0Ses3w286J1ZfBnwl1TJY8QnuJto9MSwj00QG0bTJZUjgpHAClVdqar7ganAeVFxFDjU+94a2JhCeYwY+IvF/N1E42ETxIbRdEnlZHE3ILhD2XrguKg49wLviMgtQEvg1BTKY8Rg0ozlxDuu1PYRMoz0oKEni8cDk1U1DzgLeFZEqsgkIjeISIGIFNgB9XVHUUkp02avr3J2gI+NAgwjPUjliGAD0D1wneeFBbkeOANAVT8VkRygPVAUjKSqTwJPgju8PlUCNxV8F9BHLh+W0OVz0ozl7I86dN5GAYaRfqRyRJAP9BWR3iLSDDcZ/FpUnLXAWAAROQrIAazLf4D4LqDVTe5+unIb0VrVRgGGkX6kbESgquUicjPwNpAJPKWqC0XkfqBAVV8Dfgz8VURux00cX6vxDNZGUrijJJ0L6PSCdUwY26dyVBA9Uhh9ZEfWbl/Npz8bS/tWzRtYcsMwGoqUzhGo6puqeqSqHqGqv/LC7vGUAKq6SFVPUNUhqjpUVd9JpTzpwKQZyytdQKNdPoMjhbXb9/CPT1Zz0pEdTAkYRppjW0w0IfzJX38pgL8QbMLYPqDwgjdSmFawjqWFJYRUkYYV2TCMgwBTBE2IX76+iPKog+X9UcG23fsqvYNCFRXM9uYBPlq+laJdpbaPkGGkMQ3tPmrUIf9btoVoT9CykPLZV1t5a0FhZVh5BZWjBlsxbBiGKYImQv6qbZSUlnPV8T1Y/eA43v/JGDIErjyuB+t37q3iHeRj+wgZhmGKoIkw8aUvAdhbFgKgd/uW3D1uABt27qU0wdYRYKMCw0h3TBE0Aeau3cGqrXsAeP2LTZW9+7MHd+GTr7YB0Dwrg1n/N5YBXQ6t8rytHTCM9MYmi5sAT328CsEtxPB79w+cP5BJM5ZXnilQ4YW/eeuoBpXVMIyDDxsRNHKKSkp5Z+HmKofLL9pYHLGPkM0FGIYRD1MEjZw7X/6ystfvE1Ll1qnzYobbXIBhGNGYaagRs27HHv67pKhKeFlIWbv96yq7itpcgGEYsTBF0Ij56bT5AIzt35G/X3tsA0tjGEZjxRRBI2Vz8V4+X7kdgI9X2OrgRsHjJ0Lhl1XDOw+CH3xU//IkS2OVO1nilS8rB8qrmVOLVwd1WWf1UP82R9CI8A+ZLyop5aqnZlVOEJvtv5GQNxIym0WGZTZz4QczjVXuZIlXvra9qoZHx4lXB3VZZ/VQ/9LYdn0eMWKEFhQUNLQYDcLdr3zJc7PWcsGwbvxr3kZCgYPmc7IymHnHyTYq8KlpL68+ere7CuHhIZH5Z+XArfMht1Pd5HEgvcd4z3boDztWJ+4ddx7k/tbXyCGerPGIlqGmz8ciKwfa9oYti6vei1VnNXnX1clXi9+NiMxW1RGx7tmIoJHg7yyqCv+au4GMqG1DbVQQRU16efXVu83tDEMvD19LBgy9ou6UABxY7zHesz1PgCGXx34mmH59jhxi5VWdfLV9Pl6aQ6+Ant+MX2eDLgmHSWbN3nUi+fy86/B3Y3MEjYRJM5ZX7iwaUgiZR1BVqutFSQZc+Df4+6lVw0ffkVrZfPqdCQVPue9aAQV/dx+fZHuu8XrZoyfCvOciwyQD1nwC97ZOLFuH/i5u9LOj74DF/47/XGX9aey866pua9uLjyXD6Ikw9581SyezOVSUg4aSK/OnjwYCtWb1EOs9RqdfhyQcEYhInoj8RET+JSL5IjJTRP4iIuNiHTIf4/kzRGSpiKwQkTtj3H9IROZ5n2UisvMAytJk8UcDwbY/x9syYvWD4yo/ab9qOJleVJdBMPCicLxU9MoTsfjfrnfo5x0tYzI910S97NzOrjzBuPF6rtFp9jzBxc3M9gLFXbfqCLOegBaHOZk79A/UX6Cnm9sZBl9WNe+6qtsa9eIzwvINvrSqDM1aQXaL8HVms7AibH9k+B0Fw4ddCb1PcuFHnhEuc7DOgr+n8lJo0xMQGH5tzeohtzP0+EZs+VLwe407RyAiTwPdgNeBAtyB8jnAkcDJwDHAnao6M87zmcAy4FvAetwZxuNVdVGc+LcAw1T1O4kETsc5grtf+ZLn89dFzAnYIfMxiGWDT4bxL0C/M5LrfR+oh8mI62H7StdDL/wSQvsi04i2++4qhD8Nrj5ekF2F8NDRrvea2Rxu+xLQxHXjp1ldvOxD4DvvuFGVH+dHi+HQrlBRAbs3w0MD3GjHT/O5b9dsVFObuYpM75S90L7I78mSlQPXvwdvTYQzfhsuXzD8oslQsh6mXAYXT4ZeJ7hnty6Hx74Jof1xEvc3gImiurmTf90Mc5+tKt9Fk2ulCGo7R/AHVT1NVSep6iequkJVF6jqy6p6CzAG2Jjg+ZHAClVdqar7ganAeQnijweeT1yU9GTO2p0RSgDMFBSTyt6wN4Hi96IgHBZNVg588mdQTa73faAeJiOug9N+Cd+b4XqYGdnhOLF6rrmdoeNRkelU1yPcsxW6DnPfOw8K91yPOicqYqCe/DRLi6Flh/hlGDLejaqC9Vy4wP1d8R5MPis8cdz3dJdmTUc1ieYq8o6NDAv21oddGfk9WMa4eE2gP1q87j/h8vm9bz88txN0OwZ+ujysBAC2LImvBDKbQYd+gVFWEuX32bwAWnWJLUcdE3eOQFUXRIeJyBHAIar6pde4J5qd7AasC1yvB46LFVFEegK9gf/GuX8DcANAjx49EmTZ9CgqKSXTmxm+79yjueabvRpWoIOd0RNhzjNQURaeE3j9tqq978zm0GUw7FwLaz6C+9rETi/aHhvPBh9r7iFIaH/kfEDnQXDFdJdWRZkLm/MP9/Hxe4xtesCmeZHyJBq9HHkGrJ/teu+hsvC9Q9pFlh+8OpFwGdd8DMXroNMg2Losss6CdTF6IhQtgi3LYPZkOPI093ffbrjkWXj8BKd8Kussyh4fXa/V2f/9+otO48K/uV6yb6/fsjj8fdMXVd97NJnZ7ncQaw6hMq0oKipg10Zoneeu133uFHqXQU4pBpVCxG8j8C5i/R6Co4P9e2DTfBj5XVeGFM9hJe01JCJ3Af8H3Coiz9axHJcB01U1FOumqj6pqiNUdUSHDnF6K02USTOWs2BjMeMGdebiEXkNLc7BT25nGH51ZC/K7337vczMZu76u++5ydt4xOp953aGrsPD176NvMsg50pYSUbVOYBgunkjo+z5EjsOwCXPOLs1OO+d6nrZW5ZCu8PhlLvhsN4QKnf3uw6HjgPDveYhnj2/fd9wGdfNciOCH3zo1Vl27LrI7QzfeQuGXwXL3oINc9zfYVdA54HQe7Tr0fpxB1yQuF5rZP/36iq6l5zbOfJ79HuXTFcfsX4HsUZi8Xrf/70fJg0PK9l1s6DbcPje+zDsqvAoLzgvFTH3EkWs0cHGuW5S+oixKRsFBImrCERkgmfn9xmiqt9R1e8CQ5JIewPQPXCd54XF4jLMLFSFoMvojMVF7N5X3tAi1R2Pn+i8WKI/j594YOmuL4CjL4Aex1ftyfsNc7A3OuZn8f9BY3lnlO93NmG/MdKQ69Xd2zrSnzwzO9LsEy/d0ROh24iqjWAwjghc+bKb8B1zZ9XyRD+zdRm07wffuAku+QdkegP/IZfCVS+F6+bku6B568hRw7rPoftxLs/REyMntqPr4vET4eM/uTr468nu70cPufCLnoJrXg/H/dZ9idOKVZ54ZDZzJqJkesnBdDOz4eJnY/8OakKngW6UUbQYyve5Rrv7yHB+GTHKGazLaPzRQfB/oF0fGPeHcLopJlHNbwPeEpFzvet3ROQtEXkHeDuJtPOBviLSW0Sa4Rr716IjiUh/oC3wac1Eb/pMmrGc8grfZbSJrRNIlc/5O3fDu/dU7UX5ve9or4vczjDs6sheYivPpNH/7Ko9saxmMP55GOD9W1RpvLzroM26Q/+qvcRg/rFGLH6cz5+Af90Eh3aLLFNuZzh8DGRkRT5zSDvY9pXr5fvs2gzL3oF9u6r2mk+8FbYuhd1FsHuLm8j2G594deaT6B22bA8ZXl3M+it8vd3JC66XG6sHPvSKyHry7f9BL6VEvfhYRJch2v5fm552l6Hu76Z5zvwU2u+UZ6z8gu/LD+/Qv/rRQW5nOPa70KJtzeWrBYnmCJ4TkZeAn4jId4F7cL32bFUtri5hVS0XkZtxSiMTeEpVF4rI/UCBqvpK4TJgqja2Jc4pptJl1Dtl0j9PYMLYPqlfPVxT3/VE8SG+B0g00XbTZPIOsm8XrM+Hb06IfT+e3Tdo95cMOO8R57Ex8gYXFtdTqIXzjomYewjanD2bte+F4s9bxOqFBmXQCjjxdvd9wcuuXjIy4MM/wFfvw7WvOzv15gXOM8iXe/QdzqumosxNUCbzHg8fAzPuh1UzXU+3+/HQ45vV11m0zD7VzWEAHNbL/U0UJ2j/9+svmH5NiC5DojIlw2GHQ7Nc2DgPjr4QrnzJTSLHyy86vLI8ZVRBMuCkn8KX06HXqHpza65uQdkRwIvA34BfemE/B6pVBACq+ibwZlTYPVHX9yaTVroRPF3MJ3j6WJ1T3WRddG+9JvG3LK3qVbFlSfKyZTaD4g2xF0QFG7U1n7iG8fDRsdPxe8OxwodeAbOfdn/7fgt+sjR837e7B8uQ2Sy8Snjus+6e31s9+4/heH5+wfRj/XP7MhQ85cqwYTbktHaK7QRPsUkGrP7Q9fCLFkHxejcC+HqbM4fldnL2/Vvne88WOPOFryx8uYPvsctQ1+vctgIGXQTXRw3249VZUOZg+f3y5Y2EzYucuSiY95FnwCk/j1+vZAAVkfb/ZOovEdFlSFSmZMjIgC5D3IigeSvoE+UkkOh3Fl2e9ke6UVhoP5XrNvbtgpeuh/MeDXg/pZZEcwSTgduAXwA/UtXvAX8B/ioi98R7zqgb5qzdWb/nCVQ3WRfdE0s2/uiJzjXzQJAMOPL06k1JKz9w7qDdj695HqMnRs4rVISc7TdU7u5FT+YGy5eMzTk6/bhxvuFcBmdPdopNQ2GTiv931UznXdSiLZz9sAvzFx9lZEDbntCijWevjurrRcuYkQm3L3JzD6Fyaky88sfL+6zfhxdyjZ7o5iKCZGbHtv8nU3/1yYm3wUkT4aM/OYVXU/zyXPi3gHlRXdnXfe4ufXNTPZBoQdkXqjrE+z5XVYcF7p2nqv+qJxkjSKcFZYXFpRz/6xn88ryjueobvVKbWU0XYyWzEVkySKYzhXTo52zbFWVELMDJyILh17h/nFgbtsXb9OtANzpb+ApMuxa+OwPyRsCjx4VHMZnNnHeI3/N//Ueud3fMdZGjgdqQyJyjwOZYozBxE8On/wrmPOvq85hrwrLNfcZNCEfLXV1+ydZfvPK//qOwK6+f99h74JNJ0Odb0PMb8MTosGtsLPkORup6W2i//sC9u7pKN4raLih7S0TeFpH/AlOCNxpKCaQbJaVlDO3ehgFdD019ZrmdIzcWy8iO7+VQuR3B5WEPiUTxg0hmpEvioEtcg3Dh38JpZTYL+7mL5+Oe29ktuIqeUI236deBTjr38rbrWPm+U1Bbl8f3eqnL3mreyPiLj7qPJKabaauOsPYzdz37aVjwUqRsibx16mLSPl75Y3nQZOXAp3+BRf9yk9Nblh64F099U9eODn799Tyh6v9QPW2ImHAbahE5FKhQ1d0plyRJ0mZE0BCHgeQ/BW94k5RZOc7u/MVU72Y15h0//vwX3IrS5W9H9m78nv/gy2DRK+Hl+8GtEoI9S4g9aeyT2QxuW0DMLRHqYmvnRHMgI65PXa810VbVKDw0MLwAzb936XNu0Vn7vvDr7jB0PJz1u3CcRCOWVG+NHZ13Q9VrXZKqOttVCA8Pdi6pdZmuR61GBCJyJbA7nhIQkSNE5ACdvo241PdhIKEy+PQRyGkbdn079V7XWx9yGdWuPfTj9zgeznnY/eMHe+9+z/9b98V33wv2LEdPhFad4rvZHdo1ctMvX7662ugsb2RV19CMbOdamspea+UmZjFcSf3FctH3+p4KHY6EXZtg/67w4jOfRCOWWNty1OWmZtF5542s2uutj3qtS+Jt7HegdZbbGYYmWMSXQhLNEdwKfAeY7X224Dad6wOMBrbiNp1bnnIpA6TNiGBXIfv/MIhmBDwqats7qOlGadmHwIR54XwSzR/4WzVc+lzVzdL8Z6Ll3lUI06+rfvOsXYXwp0FR3jrN3UTonq3w4yXOLLLgFZh+bbhMddGDipV3XR8ikyjvRHUXfa9VR7el8pYlTplf/Vp8z6ma5peKsjVUvdYlqaqzFL6LWo0IVPVhYDhu7UAHYKx3vQG4SlW/Xd9KIJ2oaNmJ6RWjqfBfUUZW7XsHNT2kZcj4+IuxOvSnsveYkZ14iX68nn+i5fvRaQy7koje6rAr3YpVDTkfdlX49M+Q3fLAFgnFynvI+KoLtuqjsaqu7qLvibgVvp8+4r2jfnWXX13j93p96rNe65JU1Vl9vosAdlTlQcqabXu46Hev8HnOLWRQcWC9g3g2zevfi9xO2A+PlY/fi4/eore67ZCT6fknK3t12xpHj2QOlPrsKcfKO17dRd+ri/mkunhXydKQ9VqXpKrOUpSuHVXZCFlauIsttKX8EG+TvQPpHeR2hv7jwtcRm2FdHn/7g+g0Ym3Rm0imZHv+1ckenV/eyLA3SrBM0SOZA6WBemeVeceru+h7sezuNZ1Pqot3VZO8Gqpe65JU1Vl9vgsPO6ryIGXZ5l2Akl2xz/WagnvHxCNRz3Dgt8NuhUE3vf7nhI9OTNZ970CX6NeUWFsEzHvOLfrySZXrYX2XtTaMnuit7q2H+qgrGkO9phE2IjhIObxDK649pj1yaFc3hJ75++ofSuRpdOLtzq0T3IrFym2HPf9zf3l7sht51WePJTq/RJ41qc77YKTS7p4iz59U0BjqNY1IakQgIuOAo3FeQwCo6v2pEiodKSop5ebn5/LI5cPomJvDWYO6cNagLsCnbgHO2z9zO0S26pj4KL9ol8cqG7kJHHFK+P7if0O3YyEru3H1zqI3imtMsqeCMXfAF1Ncp8Hqw6gh1Y4IRORx4FLgFlyX42KgZ4rlSjsmzVhO/urtTJqxgk079/Ltxz6haJc3idtpgPu7eaH7m+gov+BWvtFkNoMR33H7pIBbMVu0CAZ9u/H1zpqKnbmusPowDoBkTEPfVNWrgR2qeh/wDdwB9kYdUVRSyosF61CFF/LXcufL85m9Zgdzn/gBTLsOOh7tRfQ2t4q1WZffCxx8SdWJ1Og4qlBaAku8g0OCE8mNiYNtI7KGxurDqCXJKIK93t+vRaQrbhPtLqkTKf2YNGN55QYOZSHlf8u2ApC3ay77dm+HVh2gZcfwpme5naH/ueEEfJtwRiZMPtspDslw+6ZHr7ht1RGeGAVv/tTtt3/1a257gsaI2ZkjsfowakkyiuB1EWkD/A6YA6wmyWMlReQMEVkqIitE5M44cS4RkUUislBEpsSK05QoKinlkic+rTT7+AfQRG85nUmIPmwg/2tP535/Jpz9p3CE0x8I9Py9jdnmTXH70HzrPtczvPgZd6IWhEcDT4xy8wvzp8KvOsMz59bNEZGGYTRaqlUEqvpLVd2pqi/h5gb6q+rPq3vOO+/4UeBMYAAwXkQGRMXpC/wMOEFVj8adf9CkCc4F+Nfloapbz/aSQppLGf8ubOuUxqFdwg3//q+hbC8MHu+uW3ZwPf05/3B78fceFd/nP29k1X3i62mHQ8MwDk4SbTp3ivf3Qv8DjAPGet+rYySwQlVXqup+YCpwXlSc7wGPquoOAFUtqk0hGgtFJaVMzXdzAdML1lG0q5TZa3cQirG4u7+sA2BJRZ5TGluWwr9vhR1r3M6ek4bCgPPcxHDJerivjTtlat1nkT38aLtxMoeVGIaRViQaEfi7Vp0T43N2Eml3A9YFrtd7YUGOBI4UkY9F5DMROSNWQiJyg4gUiEjBli1bksj64GTSjOWEKlyrvz9UwaQZK5hwilso9tS1IxjQJXzuwG5a8L/QYJaEurpTycq+dqdWbZoHi1+HQ9pDn7FuZXC0y2iwhx/PB99fidoYfM4Nw0gpiQ6v/4X397oU598XGAPkATNFZJCq7oyS5UngSXB7DaVQnpThzwX4wlcovJi/ln/N3UDH3OaMPrIjp/QPNsbjgLuoPDm3bK9r8DfOhWVvw8ALnKno5LvcGQDB/YKq6+H7PvjlIRsNGIaR1DqC/+dNFvvXbUXkgSTS3gB0D1zneWFB1gOvqWqZqq4CluEUQ5Mj1mH0ZSFl175yOh+aQ2ZGlDto8HAKcOe8HnY4fPaY23O+/zkuvDarbM3n3DCMAMmsLD5TVe/yL1R1h4icBdxdzXP5QF8R6Y1TAJcBl0fFeRUYDzwtIu1xpqKVScreqIh1GL0CbzT7GUdvWwP3Jng41rkBUy4O7y5Zm1W2tteLYRgeySiCTBFprqr7AESkBdC8uodUtVxEbgbeBjKBp1R1oYjcDxSo6mvevdNEZBEQAn6qqttqW5iDmTdvHRVxffcrX/JCwTrmVPSlj2yguZTHftA/N2D7yqgDWqLmAYZe4Y4ErOl+QYZhpD3JrCN4DpghIteLyPXAu8A/kklcVd9U1SNV9QhV/ZUXdo+nBFDHj1R1gKoOUtWptS1IY+DZT1dz2kP/Y/XWPZVrByaVX4BGH0geRDLcwe7RE8KpPEDdMIy0Ipl1BL8BfgUc5X1+qaq/TbVgTZFlm3ezqbiUv324snK+YAttmRYazT4NDs6idpH01wMkmgewVaWGYdQSO6EslcTZJfSrzMMZuyc8355HEf9t/hOaSbk7kxcgtC/y9KamcqqTYRgNQqITymLOEYhIK1Xd7X0/HngE6IebG8gE9qjqobGeNQLkjXQLwQK2/TKyOGLYyaw+O7DR28r/wTPlgHhn9FLV3l+beQDDMIwkiDdZfKW3wdwvcErgCuBx4FTgamz30eQIevN4ZFMeeT5A50HQ51tugVfeCM/Gr7E9eszTxzCMFBBzjkBVHwe+wCkAVHUpkK2qIVV9Goi5AtiIwu/Fx5sM9j1/Vn4A3UfC9e+4nn48e7/NAxiGkQLiThar6kuq+k/c9tPNgCXe4rLbceYhIxlGT4SsON62kgHHfd+tFj58TL2KZRiG4ZOM++hVXrzbgVKgB3BRKoVqUnijApUMtEN/yPROD/M9f7YsBRR6j06YjGEYRqpIqAi8raT/n6qWquouVb1fVW9X1WX1JF/jZ9MXsKuQDS36cfXO74U3e5MMOP6H0O8suP49Nz9gGIbRACRcWayqIRHpKSLNvK2kjZpSuACWvsHDXf/B9tJ2cPgVbqK4vBQeOSYyrr9lhGEYRj2SzBYTK4GPReQ1YI8fqKp/TJlUTYkdq0EymFvcin5dW7o5gyWvw+4tQOBAGjscxjCMBiKZOYKvgNe9uLmBj5EMO1ajh3Zj9Y799Gx3iJsz+P7M8FyBj20HbRhGA1HtiEBV76sPQZosO1azL7cH5ZuVXu1burDczm7h2OynQSvscBjDMBqUahWBiLwPVNmHQlVPSYlETY3sFoRa9+GHeUcwrHubcHjl4TClNhowDKNBSWaO4CeB7znAt4E4eyYbVbjmNfaUlFLw/FyuPaFXONy2jDAM4yAhGdPQ7Kigj0VkVorkaZI8+NYS8ldvZ9KMFTxw/sDwDdsywjCMg4Bkjqo8LPBpLyKnA62TSVxEzhCRpSKyQkTujHH/WhHZIiLzvM93a1GGg5KiklJ+OelRih4eQ/7cOajC9IJ1FO0KnDRmW0YYhnEQkIzX0GygwPv7KfBj4PrqHvIWoz0KnAkMAMaLyIAYUV9Q1aHe529JS36Q89u3l6CbF9Nxx1x2awsAQqpMmrGigSUzDMOIJJmDaXqr6uHe376qepqqJrPqaSSwQlVXeovRpgLnHajAjYHCnXt5afYGuksRu7QFOzxv27KQVh0VGIZhNDDJeA3dBDynqju967bAeFX9SzWPdgPWBa7XA8fFiPdtETkJWAbcrqrroiOIyA3ADQA9evSoTuT6Ic6hM3QexB/bPwpAdylinXYkuPuoPyqImCswDMNoQJIxDX3PVwIAqroD+F4d5f9voJeqDibBWciq+qSqjlDVER06dKijrA+QvJHhoyN9Mpvxdadj+Ne8jSjQQ4pYqx0jopSFlDlrdtSfnIZhGNWQjPtopoiIemdaerb/ZtU8A7AB6B64zvPCKlHVbYHLvwGN5yzkGIfOIBncW3w2oYoyAJZrN+ZV9CE7U7j02B42CjAM46AkmRHBW8ALIjJWRMYCz3th1ZEP9BWR3t55BpcBrwUjiEiXwOW5wOLkxD4IyO0MQy8PX2dk8fWAy5i2ZD/lFW793U1lt/HX0Nk2CjAM46AmmRHBHTj7/I3e9bvAX6t7SFXLReRm4G3cQTZPqepCEbkfKFDV14AJInIuboHaduDamhehATlpIsz9pzuTuKKcQ+ZPZlXO5PB9203UMIxGgHgWn+QfEBkFXKaqN6VGpMSMGDFCCwoKGiLr2Lz+Iyj4O0rkgZQqmUh2C7jpc2id11DSGYZhACAis1U15sEnyYwIEJFhwHjgEmAV8HLdideI2V0EbXpA58FUFC4iM7DzhmgI9u+Gh452ATY6MAzjICXuHIGIHCkivxCRJcCfca6goqonq+qf603Cg5ktS+C9X7DjxF/wQsXJ7FOnV6sMsuysAcMwDmISTRYvAU4BzlbVE73GP1Q/YjUS9roJ4Ofml/BI6AI0wjgUwHYXNQzjICaRIrgQ2AS8LyJ/9TyG4rR0aYqnCGZtho2hNkwLjaZChaXajTL1zia2swYMwzjIiTtHoKqvAq+KSEvc1hC3AR1F5DHgFVV9p14kPJjZuxOAZ354Gh+u3ct7n+dQUbqH/uN+B38/FcpDNhowDOOgJ5m9hvao6hRVPQe3KGwuzqXU2LsDMrKhWUvmry/mHwtKKb/mDegyyI0CJMNGA4ZhHPQk5TXk420v8aT3MU68zR05KUJhcSltDskmJ9szCdlZA4ZhNBJqpAiMKFq0dR9gU3EpnQ/NCd/zzxowDMM4yElmiwkjHvOmwMJXASgs2Uvn1jmJ4xuGYRyEmCI4ED77C3zxPAAtsjPp3b5lAwtkGIZRc8w0dCDsLYZObkfRaT/4ZgMLYxiGUTtsRHAg7N1ROUdgGIbRWDFFUFtCZbB/F7Roy4INxVz6xKcs3lTS0FIZhmHUGFMEtaW02P3NacOqrXv4fNV2MsQWXhuG0fiwOYLackg7uGM1ZGRT+HkRgHkNGYbRKEnpiEBEzhCRpSKyQkTuTBDv2yKiIhJzr+yDEhE3P9C8FYUlpbTIzuTQHNOrhmE0PlKmCLyzjR8FzgQGAONFZECMeLnArcDnqZIlJWxeCO/+AnYVUlhcSpfWOYiZhgzDaISkckQwElihqitVdT8wFbd5XTS/BH4DlKZQlrqncAF8/CfYv4dOh+ZwTE/zHjIMo3GSSltGN9xhNj7rgeOCEURkONBdVd8QkZ/GS0hEbsCdm0yPHj1SIGot8LagJqcN95zTrmFlMQzDOAAazGtIRDKAPwI/ri6uqj6pqiNUdUSHDh1SL1wylO50f3NaN6gYhmEYB0oqFcEGoHvgOs8L88kFBgIfiMhq4HjgtUYzYbx3BzRvzZavQ4z+3fu8taCwoSUyDMOoFalUBPlAXxHpLSLNgMuA1/ybqlqsqu1VtZeq9gI+A85V1YIUylR37NsFLVqzqXgva7Z9TYbNExuG0UhJ2RyBqpaLyM3A20Am8JSqLhSR+4ECVX0tcQoHOef/Bcr3UbjUzRXYGgLDMBorKXV8V9U3gTejwu6JE3dMKmVJCVnNKSxxzk6mCAzDaKzYCqja8u490KE/hcXDycoQ2rds3tASGYZh1Arba6i2zH0O1ufTpkU2rVtks3XPvoaWyDAMo1aYIqgNqpVbUK/d/jXbv97PpBkrGloqwzCMWmGmoVg8fiIUfllttML9OUybvR5VmF6wjglj+9Ax1+YKDMNoXNiIIBZ5IyGzWdzb5Z7+fPjjLewrrwAgpGqjAsMwGiXpOyKI1+vvPAiumA7z/hn30ZAKX9OCrRWtKsPKQmqjAsMwGiXpOyKI1evPbObCcztDr9GBG+FqKiOLF0KjGbzv77xbEbkI2kYFhmE0RtJXEYyeCBJVfMmA0Xe4750HhsMzsyvjlmsGfy6/MGaSZSFlzpodqZDWMAwjZaSvaSi3Mwy9AmY/DVoBkumuczu5+8XrILsllO+FYVdC0WJY+wnvVBzL0RmruChzJneVfZe9ma249NgePHD+wMT5GYZhHKSk74gA3KgAb5OgjMBoANzBM3nHQo/jXfipvwBgcUUe/WUdZ2d+zn6ybBRgGEajJ31HBOBGBbmdoWQDDLs6PBqoCMHX2+DI0+HUe11Yq45w2OH0LhVaZyvsbs6SX1/gjqw0DMNoxKT3iADg3D9Dp4Ew6sduoRhARib8eCmMuSscTwS9aRa/3HMhHbK+hhZtTAkYhtEkSO8RAUCfsVC+D/58DNz4MbQ7woWLQFakV1Hh7nJ27yunfdZeyLCjKQ3DaBo0fUWQaL3AVa/Cyg/gkHZuUnjjXKcIPn8SNs2D8x6N6PWv2LidF5vdR8/NS6HfuPoqgWEYRkpp+qahROsFNsyGl6537qGZzV3jD7DiPdg4r4rpZ8AbFzAyY6m7WPoG3NvafR4/MeXFMAzDSBUpVQQicoaILBWRFSJyZ4z7PxCRL0Vknoh8JCID6lyIROsFtn3lrjv0h05Hu8YfnMdQp6qihLodS0V0lflKxTAMo5GSMkUgIpnAo8CZwABgfIyGfoqqDlLVocBvcYfZ1y3+eoEMzwqWkRVeL7D9K2je2pmGug6FTfPdrqIl651iiKLj2T8nIzMzMlCi3E4NwzAaGakcEYwEVqjqSlXdD0wFzgtGUNWSwGVLQFMiyeiJzhOo8tpruLd9Be0Odyago86Fb94cHhV0jFQEqsqiXYdQPujScGBms8hFaIZhGI2QVCqCbsC6wPV6LywCEblJRL7CjQgmxEpIRG4QkQIRKdiyZUvNJcntDEOvdN8P6RBuuLd/BYd5XkJHnOwtMFOnBKJGBNv27OesSR8yLfcayPJOI7PRgGEYTYAGnyxW1UdV9QjgDuDuOHGeVNURqjqiQ4cOtcto9ETI7QKlOyFU7sKufQPG/jwcZ+8OaNsLfvgJtI7UWcs37wYgr0dvp1Qkw0YDhmE0CVLpProB6B64zvPC4jEVeCxl0uR2htN/BW9OdPsIHdYb2vQI30/kZvqDj1hRtAuAvh1zofNE2LLYRgOGYTQJUjkiyAf6ikhvEWkGXAa8FowgIn0Dl+OA5SmUBwacDz9d4ZRA4Zfw8cOwd6e7lzeyqndRwCNoedFucptn0enQ5k6pXPcfGw0YhtEkSJkiUNVy4GbgbWAx8KKqLhSR+0XkXC/azSKyUETmAT8CrkmVPICbMPbXBqz8AN69x+08Cp6badSWEYE5gIUbSqhA2bLbDqk3DKNpkdKVxar6JvBmVNg9ge+3pjL/mOT/HRa+Au36QIu2cMhhLjy3Mwy4ABZMd9dRHkGHtczm630hJs1YYVtOG4bRpGjwyeJ6J7QfVn8Iqz8Kewz5nP4ryPKOmQyMBopKSpm5fCuKO6S+aFdp/cpsGIaRQtJPEXT3VgFvWx7eYM7HX3wW5RF085S5hCrcEgc7jtIwjKZGeimCx0+Ev54Svp7/QtW9gkZPDB9GAyzaWMys1dsp9xSBf0i9jQoMw2gqpJciSLQBnU+UR9CPXvyiSjI2KjAMoymRXoqgugPro1iyqYQlhbuqhNvxlIZhNCWa/nkEQfw5gLnPuknjavYK8kcD5w7pyqTxw+pTUsMwjHojvUYEEDkqSDAaKCopZdlmNxp4Z2GhzQkYhtFkST9FEMczyKeopJRLnviE37y1pHJ9mc0JGIbRlEk/RQBVPIOC/PHdZcxatYNX5m6gLGSeQoZhNH3SUxHE2Stow46vebHA7ZxdEXUygo0KDMNoqqSlInDmn0+r9PC//+zsKgrAxzyFDMNoqqSX15DHpBnLyV+9PWLfoHcXFrJgY0lEvJysDGbecTIdc3MaQkzDMIx6Ie1GBEUlpUybvR5VmFawjkUbi7nkiU/504yqO2CbOcgwjHQg7UYEk2Yspyzktp7eV17B+L9+Rsnectockl0lrpmDDMNIB9JKEfijgeA8QPFed2zl3v0hZv3fWDMDGYaRdqTUNCQiZ4jIUhFZISJ3xrj/IxFZJCLzRWSGiPRMpTyTZiynQmPPBpsZyDCMdCVlikBEMoFHgTOBAcB4ERkQFW0uMEJVBwPTgd+mSh6AOWt3Vq4NiMbWChiGka6kckQwElihqitVdT/ucPrzghFU9X1V/dq7/Ax3wH3KePPWUdx/3tG8ddsorjyuB9mZkUdT2qjAMIx0JJWKoBuwLnC93guLx/XAf1IoD5tLSrnnXwt5d+HmmKMDmxw2DCMdOSgmi0XkSmAEMDrO/RuAGwB69OhR63zeWbQZgNMHduaWsX1rnY5hGEZTIpUjgg1A98B1nhcWgYicCvwfcK6q7ouVkKo+qaojVHVEhw4daiVMUUkpv3trCT0Oa0Hfjq1qlYZhGEZTJJWKIB/oKyK9RaQZcBnwWjCCiAwDnsApgaIUysLv3l5KSWk5uTnZiEj1DxiGYaQJKVMEqloO3Ay8DSwGXlTVhSJyv4ic60X7HdAKmCYi80TktTjJHRBFJaW8Os8NRpZv3m2eQYZhGAFSOkegqm8Cb0aF3RP4fmoq8/eZFNg+QtGIPYYMwzDSnSa/15C/mtjOFjAMw4hNk1cEsVYT23oBwzCMME1eEdh6AcMwjMQcFOsIUsmbt45qaBEMwzAOapr8iMAwDMNIjCkCwzCMNMcUgWEYRppjisAwDCPNMUVgGIaR5ojGObHrYEVEtgBravl4e2BrHYrTWEjHcqdjmSE9y52OZYaal7unqsbctbPRKYIDQUQKVHVEQ8tR36RjudOxzJCe5U7HMkPdlttMQ4ZhGGmOKQLDMIw0J90UwZMNLUADkY7lTscyQ3qWOx3LDHVY7rSaIzAMwzCqkm4jAsMwDCMKUwSGYRhpTtooAhE5Q0SWisgKEbmzoeVJBSLSXUTeF5FFIrJQRG71wg8TkXdFZLn3t21Dy1rXiEimiMwVkde9694i8rn3vl/wzs1uUohIGxGZLiJLRGSxiHwjTd717d7ve4GIPC8iOU3tfYvIUyJSJCILAmEx3604Jnllny8iw2uaX1ooAhHJBB4FzgQGAONFZEDDSpUSyoEfq+oA4HjgJq+cdwIzVLUvMMO7bmrcijsb2+c3wEOq2gfYAVzfIFKlloeBt1S1PzAEV/4m/a5FpBswARihqgOBTOAymt77ngycERUW792eCfT1PjcAj9U0s7RQBMBIYIWqrlTV/cBU4LwGlqnOUdVNqjrH+74L1zB0w5X1H160fwDnN4iAKUJE8oBxwN+8awFOAaZ7UZpimVsDJwF/B1DV/aq6kyb+rj2ygBYikgUcAmyiib1vVZ0JbI8KjvduzwOeUcdnQBsR6VKT/NJFEXQD1gWu13thTRYR6QUMAz4HOqnqJu9WIdCpoeRKEX8CJgIV3nU7YKeqlnvXTfF99wa2AE97JrG/iUhLmvi7VtUNwO+BtTgFUAzMpum/b4j/bg+4fUsXRZBWiEgr4CXgNlUtCd5T5y/cZHyGReRsoEhVZze0LPVMFjAceExVhwF7iDIDNbV3DeDZxc/DKcKuQEuqmlCaPHX9btNFEWwAugeu87ywJoeIZOOUwHOq+rIXvNkfKnp/ixpKvhRwAnCuiKzGmfxOwdnO23imA2ia73s9sF5VP/eup+MUQ1N+1wCnAqtUdYuqlgEv434DTf19Q/x3e8DtW7oognygr+dZ0Aw3ufRaA8tU53i28b8Di1X1j4FbrwHXeN+vAf5V37KlClX9marmqWov3Hv9r6peAbwPXORFa1JlBlDVQmCdiPTzgsYCi2jC79pjLXC8iBzi/d79cjfp9+0R792+BlzteQ8dDxQHTEjJoapp8QHOApYBXwH/19DypKiMJ+KGi/OBed7nLJzNfAawHHgPOKyhZU1R+ccAr3vfDwdmASuAaUDzhpYvBeUdChR47/tVoG06vGvgPmAJsAB4Fmje1N438DxuDqQMN/q7Pt67BQTnFfkV8CXOo6pG+dkWE4ZhGGlOupiGDMMwjDiYIjAMw0hzTBEYhmGkOaYIDMMw0hxTBIZhGGmOKQLDCCAiGSLyloj0aGhZDKO+MPdRwwggIkcAear6v4aWxTDqC1MEhuEhIiHcghyfqar6YEPJYxj1hSkCw/AQkd2q2qqh5TCM+sbmCAyjGkRktYj8VkS+FJFZItLHC+8lIv/1ToWa4c8riEgnEXlFRL7wPt/0wl8Vkdne6Vo3eGGZIjLZO23rSxG5veFKaqQrWdVHMYy0oYWIzAtc/1pVX/C+F6vqIBG5Gnf+wdnAn4F/qOo/ROQ7wCTcYSGTgP+p6gXe6Xj+KOM7qrpdRFoA+SLyEtAL6KbutC1EpE0qC2gYsTDTkGF4xDMNeVtcn6KqK71tvgtVtZ2IbAW6qGqZF75JVduLyBbchPO+qHTuBS7wLnsBpwNLcRvHvQm8AbyjqhUYRj1ipiHDSA6N8z0pRGQMbi/9b6jqEGAukKOqO3DnDX8A/ADvuE3DqE9MERhGclwa+Pup9/0T3BkIAFcAH3rfZwA3QuUcQGugNbBDVb8Wkf7A8d799kCGqr4E3I07XMYw6hUzDRmGRwz30bdU9U7PNPQCcCawDxivqitEpCfwNNAed37wdaq6VkQ6AU/i9sgP4ZTCHNyZAb1w5qA2wL3ADi8Nv1P2M1X9T8oKaRgxMEVgGNXgKYIRqrq1oWUxjFRgpiHDMIw0x0YEhmEYaY6NCAzDMNIcUwSGYRhpjikCwzCMNMcUgWEYRppjisAwDCPN+f9pG7VWofPcKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(acc, label='treino', linestyle='dashed', marker='^')\n",
    "plt.plot(val_acc, label='validação', linestyle='dashed', marker='v')\n",
    "plt.legend()\n",
    "plt.title(\"Acurácia vs epoca de treinamento\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Acurácia (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e098fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = torch.tensor([]).to(device)\n",
    "ground_truth = torch.tensor([]).to(device)\n",
    "for batch in test_loader:\n",
    "    data, targets = batch[0], batch[1] # next(iter(test_loader))\n",
    "    data = Variable(torch.Tensor(data.float())).to(device)\n",
    "    targets = Variable(torch.Tensor(targets.float())).to(device)\n",
    "    output = model(data)\n",
    "    loss = criterion(output, torch.flatten(targets.long()))\n",
    "\n",
    "predictions = torch.cat((predictions, output), 0)\n",
    "ground_truth = torch.cat((ground_truth, targets), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e489c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.cpu().detach().numpy()\n",
    "predictions = np.argmax(predictions, axis=1).reshape(predictions.shape[0], 1)\n",
    "ground_truth = ground_truth.cpu().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31efff9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mtx = confusion_matrix(ground_truth, predictions)\n",
    "\n",
    "conf_df = pd.DataFrame(conf_mtx, index = [i for i in range(5)],\n",
    "                  columns = [i for i in range(5)])\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "labels = [name[2:-4] for name in listdir(feat_dir+'/train')]\n",
    "sns.heatmap(conf_df, cmap=sns.cm.rocket_r, square=True, \n",
    "            linewidths=0.1, annot=True, fmt='d', annot_kws={\"fontsize\": 8},\n",
    "           xticklabels=labels, yticklabels=labels)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e05bbb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Acc:\t 0.720\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(ground_truth, predictions)\n",
    "print(f' Acc:\\t {acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180426e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
